{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.impute import SimpleImputer\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 6.15 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df=pd.read_csv(\"train.csv\")\n",
    "df_test=pd.read_csv(\"test.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0    474018\n",
       " 1.0    107979\n",
       " Name: bin_1, dtype: int64, fc8fc7e56    977\n",
       " 360a16627    972\n",
       " 423976253    961\n",
       " 7917d446c    961\n",
       " 079b76328    960\n",
       " 879c2ed83    960\n",
       " f4c4a7cc2    958\n",
       " e32171484    956\n",
       " 251c8292d    954\n",
       " b2894f509    951\n",
       " b165c9589    951\n",
       " 124963b67    950\n",
       " edd08fbe3    948\n",
       " bcdb1d6a1    947\n",
       " 094b85efd    947\n",
       " 691ebeae8    945\n",
       " 3ad40eeef    945\n",
       " b33e135b5    944\n",
       " 03ea75c83    942\n",
       " c8a903ab9    941\n",
       " 4d701cd2a    941\n",
       " 207bec5ff    941\n",
       " 606509f50    940\n",
       " 8e0f7217a    938\n",
       " b8f70e10b    936\n",
       " 9e0154a54    934\n",
       " 0d475c15f    933\n",
       " 7d6c0cf07    931\n",
       " e32849ce1    929\n",
       " c9b03bd0c    928\n",
       "             ... \n",
       " 8567e3930     22\n",
       " ee0884cf8     20\n",
       " 471b15c2f     19\n",
       " 4b93c32fd     18\n",
       " abd477977     18\n",
       " 1b88f3b6a     17\n",
       " 7d7c614e7     16\n",
       " ba3ec5b4e     16\n",
       " 4a5e9c714     14\n",
       " d48b41023     14\n",
       " 7b1a1b48c     14\n",
       " f4ace1f90     13\n",
       " 8116aba72     13\n",
       " b578ca3d3     13\n",
       " 15d09c0f3     13\n",
       " 58aa1b824     12\n",
       " e8dca2f17     12\n",
       " 44a2e6186     10\n",
       " 89f532300     10\n",
       " 7331b57f0      9\n",
       " f00b62582      9\n",
       " 53554f740      9\n",
       " 6ed2e8c60      8\n",
       " 0ce611b68      7\n",
       " d1d7d8352      7\n",
       " 7335087fd      5\n",
       " 30019ce8a      3\n",
       " d6bb2181a      1\n",
       " 0385d0739      1\n",
       " b3ad70fcb      1\n",
       " Name: nom_5, Length: 1220, dtype: int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.bin_1.value_counts(),df.nom_5.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    487677\n",
       "1    112323\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.apply(lambda group: group.interpolate(limit_direction='both'))\n",
    "for col in df:\n",
    "    if df[col].isna().sum() > 0:\n",
    "        df[col] = df[col].fillna(df[col].mode()[0])\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna('-99999',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600000, 25)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().any().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.23 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import numpy as np\n",
    "features_cyc = ['day', 'month']\n",
    "for feature in features_cyc:\n",
    "    df[feature+'_sin'] = np.sin((2*np.pi*df[feature])/max(df[feature]))\n",
    "    df[feature+'_cos'] = np.cos((2*np.pi*df[feature])/max(df[feature]))\n",
    "    df_test[feature+'_sin'] = np.sin((2*np.pi*df_test[feature])/max(df_test[feature]))\n",
    "    df_test[feature+'_cos'] = np.cos((2*np.pi*df_test[feature])/max(df_test[feature]))\n",
    "df = df.drop(features_cyc, axis=1)\n",
    "df_test = df_test.drop(features_cyc, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().any().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_missing_train = [col for col in df.columns if df[col].isnull().any()]\n",
    "cols_missing_test = [col for col in df_test.columns if df_test[col].isnull().any()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bin_0',\n",
       " 'bin_1',\n",
       " 'bin_2',\n",
       " 'bin_3',\n",
       " 'bin_4',\n",
       " 'nom_0',\n",
       " 'nom_1',\n",
       " 'nom_2',\n",
       " 'nom_3',\n",
       " 'nom_4',\n",
       " 'nom_5',\n",
       " 'nom_6',\n",
       " 'nom_7',\n",
       " 'nom_8',\n",
       " 'nom_9',\n",
       " 'ord_0',\n",
       " 'ord_1',\n",
       " 'ord_2',\n",
       " 'ord_3',\n",
       " 'ord_4',\n",
       " 'ord_5',\n",
       " 'day_sin',\n",
       " 'day_cos',\n",
       " 'month_sin',\n",
       " 'month_cos']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_missing_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    551\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[1;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 553\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    554\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    555\u001b[0m             \u001b[1;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\sklearn\\impute\\_base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    266\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissing_values\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 268\u001b[1;33m                                                fill_value)\n\u001b[0m\u001b[0;32m    269\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_indicator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\sklearn\\impute\\_base.py\u001b[0m in \u001b[0;36m_dense_fit\u001b[1;34m(self, X, strategy, missing_values, fill_value)\u001b[0m\n\u001b[0;32m    356\u001b[0m                 \u001b[0mrow_mask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogical_not\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbool\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    357\u001b[0m                 \u001b[0mrow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrow_mask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 358\u001b[1;33m                 \u001b[0mmost_frequent\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_most_frequent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    359\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    360\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mmost_frequent\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\sklearn\\impute\\_base.py\u001b[0m in \u001b[0;36m_most_frequent\u001b[1;34m(array, extra_value, n_repeat)\u001b[0m\n\u001b[0;32m     59\u001b[0m             \u001b[1;31m# has already been NaN-masked.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRuntimeWarning\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m             \u001b[0mmode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstats\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0mmost_frequent_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\scipy\\stats\\stats.py\u001b[0m in \u001b[0;36mmode\u001b[1;34m(a, axis, nan_policy)\u001b[0m\n\u001b[0;32m    431\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mModeResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    432\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 433\u001b[1;33m     \u001b[0mcontains_nan\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnan_policy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_contains_nan\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnan_policy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    435\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcontains_nan\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mnan_policy\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'omit'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\scipy\\stats\\stats.py\u001b[0m in \u001b[0;36m_contains_nan\u001b[1;34m(a, nan_policy)\u001b[0m\n\u001b[0;32m    235\u001b[0m         \u001b[1;31m# e.g. np.isnan(a).any()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    236\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minvalid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ignore'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 237\u001b[1;33m             \u001b[0mcontains_nan\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    238\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m         \u001b[1;31m# If the check cannot be properly performed we fallback to omitting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36msum\u001b[1;34m(a, axis, dtype, out, keepdims, initial)\u001b[0m\n\u001b[0;32m   2074\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2075\u001b[0m     return _wrapreduction(a, np.add, 'sum', axis, dtype, out, keepdims=keepdims,\n\u001b[1;32m-> 2076\u001b[1;33m                           initial=initial)\n\u001b[0m\u001b[0;32m   2077\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2078\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "imp_cat = SimpleImputer(strategy='most_frequent')\n",
    "df[cols_missing_train] = imp_cat.fit_transform(df[cols_missing_train])\n",
    "df_test[cols_missing_test] = imp_cat.fit_transform(df_test[cols_missing_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class categoricalfeature:\n",
    "    def __init__(self,df,cat_feat,encoding_type,handle_NAN=False):\n",
    "        #df pandas frames\n",
    "        #cat_feature: list of categorical feature\n",
    "        #encoding_type: lable,binary,one_hot\n",
    "        self.df=df\n",
    "        self.output_df=self.df.copy(deep=True)\n",
    "        self.cat_feat=cat_feat\n",
    "        self.encoding_type=encoding_type\n",
    "        self.label_encoders=dict()\n",
    "        \n",
    "        if handle_NAN:\n",
    "            for c in self.cat_feat:\n",
    "                self.df.loc[:,c]= self.df.loc[:,c].astype(str).fillna('-99999')\n",
    "\n",
    "    def _label_endcoding(self):\n",
    "        for c in self.cat_feat:\n",
    "            lbl=preprocessing.LabelEncoder()\n",
    "            lbl.fit(self.df[c].values)\n",
    "            self.output_df.loc[:,c]=lbl.transform(self.df[c].values)\n",
    "            self.label_encoders[c]=lbl\n",
    "        return self.output_df\n",
    "            \n",
    "    def transform(self):\n",
    "        if self.encoding_type=='label':\n",
    "            return self._label_endcoding()\n",
    "        else:\n",
    "            raise Exception(\"Encoding type not understand\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bin_3',\n",
       " 'bin_4',\n",
       " 'nom_0',\n",
       " 'nom_1',\n",
       " 'nom_2',\n",
       " 'nom_3',\n",
       " 'nom_4',\n",
       " 'nom_5',\n",
       " 'nom_6',\n",
       " 'nom_7',\n",
       " 'nom_8',\n",
       " 'nom_9',\n",
       " 'ord_1',\n",
       " 'ord_2',\n",
       " 'ord_3',\n",
       " 'ord_4',\n",
       " 'ord_5']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col=[c for c in df.columns if df[c].dtype=='object']\n",
    "col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "col=[c for c in df.columns if c not in ['id','target']]\n",
    "#col=[c for c in df.columns if df[c].dtype=='object']\n",
    "cat=categoricalfeature(df,cat_feat=col,encoding_type='label',handle_NAN=True)\n",
    "catt=categoricalfeature(df_test,cat_feat=col,encoding_type='label',handle_NAN=True)\n",
    "encoded_df=cat.transform()\n",
    "encoded_df_test=catt.transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>bin_0</th>\n",
       "      <th>bin_1</th>\n",
       "      <th>bin_2</th>\n",
       "      <th>bin_3</th>\n",
       "      <th>bin_4</th>\n",
       "      <th>nom_0</th>\n",
       "      <th>nom_1</th>\n",
       "      <th>nom_2</th>\n",
       "      <th>nom_3</th>\n",
       "      <th>...</th>\n",
       "      <th>ord_1</th>\n",
       "      <th>ord_2</th>\n",
       "      <th>ord_3</th>\n",
       "      <th>ord_4</th>\n",
       "      <th>ord_5</th>\n",
       "      <th>target</th>\n",
       "      <th>day_sin</th>\n",
       "      <th>day_cos</th>\n",
       "      <th>month_sin</th>\n",
       "      <th>month_cos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>151</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>105</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  bin_0  bin_1  bin_2  bin_3  bin_4  nom_0  nom_1  nom_2  nom_3  ...  \\\n",
       "0   0      0      0      0      0      0      2      4      3      5  ...   \n",
       "1   1      1      1      0      0      1      2      3      0      6  ...   \n",
       "2   2      0      1      0      0      0      2      6      3      0  ...   \n",
       "3   3      2      0      0      0      0      2      0      3      3  ...   \n",
       "4   4      0      2      0      1      0      2      5      3      2  ...   \n",
       "\n",
       "   ord_1  ord_2  ord_3  ord_4  ord_5  target  day_sin  day_cos  month_sin  \\\n",
       "0      0      3      2     20     56       0        1        4          9   \n",
       "1      2      5      4     23    151       0        3        6          0   \n",
       "2      5      2     13     15    105       0        2        1          4   \n",
       "3      4      4      0      2    140       0        4        2          9   \n",
       "4      2      1      7      2     50       0        2        1          5   \n",
       "\n",
       "   month_cos  \n",
       "0         10  \n",
       "1          3  \n",
       "2          5  \n",
       "3         10  \n",
       "4          9  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    528377\n",
       "1     53729\n",
       "2     17894\n",
       "Name: bin_0, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_df.bin_0.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>bin_0</th>\n",
       "      <th>bin_1</th>\n",
       "      <th>bin_2</th>\n",
       "      <th>bin_3</th>\n",
       "      <th>bin_4</th>\n",
       "      <th>nom_0</th>\n",
       "      <th>nom_1</th>\n",
       "      <th>nom_2</th>\n",
       "      <th>nom_3</th>\n",
       "      <th>...</th>\n",
       "      <th>ord_0</th>\n",
       "      <th>ord_1</th>\n",
       "      <th>ord_2</th>\n",
       "      <th>ord_3</th>\n",
       "      <th>ord_4</th>\n",
       "      <th>ord_5</th>\n",
       "      <th>day_sin</th>\n",
       "      <th>day_cos</th>\n",
       "      <th>month_sin</th>\n",
       "      <th>month_cos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>147</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>600001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>140</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>600002</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>600003</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>600004</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  bin_0  bin_1  bin_2  bin_3  bin_4  nom_0  nom_1  nom_2  nom_3  ...  \\\n",
       "0  600000      0      0      0      0      1      0      1      0      3  ...   \n",
       "1  600001      0      0      0      0      1      2      0      4      5  ...   \n",
       "2  600002      0      0      0      0      1      0      0      0      5  ...   \n",
       "3  600003      1      0      0      0      0      2      1      0      2  ...   \n",
       "4  600004      0      0      1      0      1      2      0      6      3  ...   \n",
       "\n",
       "   ord_0  ord_1  ord_2  ord_3  ord_4  ord_5  day_sin  day_cos  month_sin  \\\n",
       "0      2      4      0      5     20    147        4        2          4   \n",
       "1      0      4      1     13     13    140        6        0          2   \n",
       "2      0      1      5      8     13     12        6        0         10   \n",
       "3      0      1      3     12      1      0        5        5         10   \n",
       "4      0      0      4     15      9     14        4        2          9   \n",
       "\n",
       "   month_cos  \n",
       "0          5  \n",
       "1          1  \n",
       "2          4  \n",
       "3          4  \n",
       "4         10  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=encoded_df.drop([\"id\",\"target\"],axis=1)\n",
    "Y=encoded_df[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [     0      1      3 ... 599997 599998 599999] TEST: [     2      7     14 ... 599931 599933 599988]\n",
      "TRAIN: [     0      1      2 ... 599997 599998 599999] TEST: [     4     17     78 ... 599951 599959 599994]\n",
      "TRAIN: [     0      1      2 ... 599996 599998 599999] TEST: [    27     49     84 ... 599970 599976 599997]\n",
      "TRAIN: [     0      1      2 ... 599997 599998 599999] TEST: [    10     56     72 ... 599914 599949 599983]\n",
      "TRAIN: [     0      1      2 ... 599997 599998 599999] TEST: [     9     20     25 ... 599971 599979 599981]\n",
      "TRAIN: [     0      1      2 ... 599997 599998 599999] TEST: [     6     38     53 ... 599945 599980 599995]\n",
      "TRAIN: [     0      1      2 ... 599997 599998 599999] TEST: [    26     62     80 ... 599990 599991 599992]\n",
      "TRAIN: [     0      2      3 ... 599997 599998 599999] TEST: [     1     21     22 ... 599937 599964 599984]\n",
      "TRAIN: [     1      2      3 ... 599996 599997 599999] TEST: [     0      8     19 ... 599961 599969 599998]\n",
      "TRAIN: [     0      1      2 ... 599996 599997 599998] TEST: [    12     13     24 ... 599977 599985 599999]\n",
      "TRAIN: [     0      1      2 ... 599997 599998 599999] TEST: [     5     44     45 ... 599940 599954 599973]\n",
      "TRAIN: [     0      1      2 ... 599997 599998 599999] TEST: [    18     33     35 ... 599978 599987 599996]\n",
      "TRAIN: [     0      1      2 ... 599997 599998 599999] TEST: [    29     42     54 ... 599889 599920 599960]\n",
      "TRAIN: [     0      1      2 ... 599997 599998 599999] TEST: [    39     46     48 ... 599948 599953 599989]\n",
      "TRAIN: [     0      1      2 ... 599997 599998 599999] TEST: [     3     11     16 ... 599975 599986 599993]\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=15,shuffle=True)\n",
    "skf.get_n_splits(X, Y)\n",
    "\n",
    "for train_index, test_index in skf.split(X, Y):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    x_train, x_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = Y.iloc[train_index], Y.iloc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "months = [('month', i) for i in [2, 3, 4, 6, 12]]\n",
    "days = [('day', i) for i in [2, 3, 4, 7]]\n",
    "\n",
    "for f_p in days + months:\n",
    "    for fun_suf in [(math.cos, '_cos'), (math.sin, '_sin')]:\n",
    "        f, period = f_p\n",
    "        func, suffix = fun_suf\n",
    "        df[f + suffix + str(period)] = train[f].apply(lambda i: func(math.pi * i / period) if i == i else 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "lgbm = LGBMClassifier(objective='binary', random_state=5)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10,shuffle=True)\n",
    "skf.get_n_splits(X, Y)\n",
    "accuracy=[]\n",
    "\n",
    "for train_index, test_index in skf.split(X, Y):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    x_train, x_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = Y.iloc[train_index], Y.iloc[test_index]\n",
    "    #lgbm.fit(x_train,y_train)\n",
    "    #pred=lgbm.predict(x_test)\n",
    "    #zscore=accuracy_score(pred,y_test)\n",
    "    #accuracy.append(score)\n",
    "#print(accuracy)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.474489\tvalid_0's binary_logloss: 0.474599\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[2]\ttraining's binary_logloss: 0.469319\tvalid_0's binary_logloss: 0.469271\n",
      "[3]\ttraining's binary_logloss: 0.465137\tvalid_0's binary_logloss: 0.465112\n",
      "[4]\ttraining's binary_logloss: 0.461335\tvalid_0's binary_logloss: 0.461382\n",
      "[5]\ttraining's binary_logloss: 0.458348\tvalid_0's binary_logloss: 0.458321\n",
      "[6]\ttraining's binary_logloss: 0.456185\tvalid_0's binary_logloss: 0.456164\n",
      "[7]\ttraining's binary_logloss: 0.453905\tvalid_0's binary_logloss: 0.453752\n",
      "[8]\ttraining's binary_logloss: 0.451533\tvalid_0's binary_logloss: 0.451423\n",
      "[9]\ttraining's binary_logloss: 0.449735\tvalid_0's binary_logloss: 0.449541\n",
      "[10]\ttraining's binary_logloss: 0.448267\tvalid_0's binary_logloss: 0.448137\n",
      "[11]\ttraining's binary_logloss: 0.446532\tvalid_0's binary_logloss: 0.446341\n",
      "[12]\ttraining's binary_logloss: 0.444658\tvalid_0's binary_logloss: 0.444327\n",
      "[13]\ttraining's binary_logloss: 0.443329\tvalid_0's binary_logloss: 0.442965\n",
      "[14]\ttraining's binary_logloss: 0.442238\tvalid_0's binary_logloss: 0.44189\n",
      "[15]\ttraining's binary_logloss: 0.44127\tvalid_0's binary_logloss: 0.440889\n",
      "[16]\ttraining's binary_logloss: 0.440162\tvalid_0's binary_logloss: 0.439834\n",
      "[17]\ttraining's binary_logloss: 0.438517\tvalid_0's binary_logloss: 0.438075\n",
      "[18]\ttraining's binary_logloss: 0.437591\tvalid_0's binary_logloss: 0.437172\n",
      "[19]\ttraining's binary_logloss: 0.43676\tvalid_0's binary_logloss: 0.43644\n",
      "[20]\ttraining's binary_logloss: 0.436012\tvalid_0's binary_logloss: 0.435648\n",
      "[21]\ttraining's binary_logloss: 0.434974\tvalid_0's binary_logloss: 0.434668\n",
      "[22]\ttraining's binary_logloss: 0.434264\tvalid_0's binary_logloss: 0.43394\n",
      "[23]\ttraining's binary_logloss: 0.433403\tvalid_0's binary_logloss: 0.432994\n",
      "[24]\ttraining's binary_logloss: 0.432816\tvalid_0's binary_logloss: 0.432464\n",
      "[25]\ttraining's binary_logloss: 0.43221\tvalid_0's binary_logloss: 0.431852\n",
      "[26]\ttraining's binary_logloss: 0.431233\tvalid_0's binary_logloss: 0.430871\n",
      "[27]\ttraining's binary_logloss: 0.430688\tvalid_0's binary_logloss: 0.430335\n",
      "[28]\ttraining's binary_logloss: 0.430103\tvalid_0's binary_logloss: 0.429735\n",
      "[29]\ttraining's binary_logloss: 0.429467\tvalid_0's binary_logloss: 0.429111\n",
      "[30]\ttraining's binary_logloss: 0.428959\tvalid_0's binary_logloss: 0.428603\n",
      "[31]\ttraining's binary_logloss: 0.428427\tvalid_0's binary_logloss: 0.428011\n",
      "[32]\ttraining's binary_logloss: 0.427882\tvalid_0's binary_logloss: 0.427471\n",
      "[33]\ttraining's binary_logloss: 0.427522\tvalid_0's binary_logloss: 0.427138\n",
      "[34]\ttraining's binary_logloss: 0.427172\tvalid_0's binary_logloss: 0.426834\n",
      "[35]\ttraining's binary_logloss: 0.426674\tvalid_0's binary_logloss: 0.426343\n",
      "[36]\ttraining's binary_logloss: 0.426212\tvalid_0's binary_logloss: 0.425952\n",
      "[37]\ttraining's binary_logloss: 0.42584\tvalid_0's binary_logloss: 0.425545\n",
      "[38]\ttraining's binary_logloss: 0.425419\tvalid_0's binary_logloss: 0.425144\n",
      "[39]\ttraining's binary_logloss: 0.425001\tvalid_0's binary_logloss: 0.424735\n",
      "[40]\ttraining's binary_logloss: 0.424635\tvalid_0's binary_logloss: 0.424386\n",
      "[41]\ttraining's binary_logloss: 0.424343\tvalid_0's binary_logloss: 0.424042\n",
      "[42]\ttraining's binary_logloss: 0.424098\tvalid_0's binary_logloss: 0.423825\n",
      "[43]\ttraining's binary_logloss: 0.423822\tvalid_0's binary_logloss: 0.423584\n",
      "[44]\ttraining's binary_logloss: 0.423512\tvalid_0's binary_logloss: 0.423274\n",
      "[45]\ttraining's binary_logloss: 0.42325\tvalid_0's binary_logloss: 0.423069\n",
      "[46]\ttraining's binary_logloss: 0.422973\tvalid_0's binary_logloss: 0.42276\n",
      "[47]\ttraining's binary_logloss: 0.422651\tvalid_0's binary_logloss: 0.422447\n",
      "[48]\ttraining's binary_logloss: 0.422371\tvalid_0's binary_logloss: 0.422169\n",
      "[49]\ttraining's binary_logloss: 0.421973\tvalid_0's binary_logloss: 0.421821\n",
      "[50]\ttraining's binary_logloss: 0.421627\tvalid_0's binary_logloss: 0.421524\n",
      "[51]\ttraining's binary_logloss: 0.4214\tvalid_0's binary_logloss: 0.421302\n",
      "[52]\ttraining's binary_logloss: 0.421202\tvalid_0's binary_logloss: 0.421082\n",
      "[53]\ttraining's binary_logloss: 0.421024\tvalid_0's binary_logloss: 0.420914\n",
      "[54]\ttraining's binary_logloss: 0.42079\tvalid_0's binary_logloss: 0.420688\n",
      "[55]\ttraining's binary_logloss: 0.420605\tvalid_0's binary_logloss: 0.420563\n",
      "[56]\ttraining's binary_logloss: 0.420425\tvalid_0's binary_logloss: 0.42047\n",
      "[57]\ttraining's binary_logloss: 0.420159\tvalid_0's binary_logloss: 0.420127\n",
      "[58]\ttraining's binary_logloss: 0.420003\tvalid_0's binary_logloss: 0.419961\n",
      "[59]\ttraining's binary_logloss: 0.419819\tvalid_0's binary_logloss: 0.419786\n",
      "[60]\ttraining's binary_logloss: 0.419581\tvalid_0's binary_logloss: 0.419568\n",
      "[61]\ttraining's binary_logloss: 0.419392\tvalid_0's binary_logloss: 0.419368\n",
      "[62]\ttraining's binary_logloss: 0.419194\tvalid_0's binary_logloss: 0.419179\n",
      "[63]\ttraining's binary_logloss: 0.419039\tvalid_0's binary_logloss: 0.41905\n",
      "[64]\ttraining's binary_logloss: 0.418838\tvalid_0's binary_logloss: 0.418852\n",
      "[65]\ttraining's binary_logloss: 0.418619\tvalid_0's binary_logloss: 0.418605\n",
      "[66]\ttraining's binary_logloss: 0.418431\tvalid_0's binary_logloss: 0.418427\n",
      "[67]\ttraining's binary_logloss: 0.418277\tvalid_0's binary_logloss: 0.418297\n",
      "[68]\ttraining's binary_logloss: 0.418124\tvalid_0's binary_logloss: 0.418146\n",
      "[69]\ttraining's binary_logloss: 0.417698\tvalid_0's binary_logloss: 0.41778\n",
      "[70]\ttraining's binary_logloss: 0.417502\tvalid_0's binary_logloss: 0.41761\n",
      "[71]\ttraining's binary_logloss: 0.417205\tvalid_0's binary_logloss: 0.41734\n",
      "[72]\ttraining's binary_logloss: 0.417089\tvalid_0's binary_logloss: 0.417273\n",
      "[73]\ttraining's binary_logloss: 0.416959\tvalid_0's binary_logloss: 0.41718\n",
      "[74]\ttraining's binary_logloss: 0.416829\tvalid_0's binary_logloss: 0.417038\n",
      "[75]\ttraining's binary_logloss: 0.416711\tvalid_0's binary_logloss: 0.416912\n",
      "[76]\ttraining's binary_logloss: 0.416579\tvalid_0's binary_logloss: 0.416755\n",
      "[77]\ttraining's binary_logloss: 0.41647\tvalid_0's binary_logloss: 0.416647\n",
      "[78]\ttraining's binary_logloss: 0.416337\tvalid_0's binary_logloss: 0.416502\n",
      "[79]\ttraining's binary_logloss: 0.416221\tvalid_0's binary_logloss: 0.416391\n",
      "[80]\ttraining's binary_logloss: 0.416069\tvalid_0's binary_logloss: 0.41618\n",
      "[81]\ttraining's binary_logloss: 0.415952\tvalid_0's binary_logloss: 0.416069\n",
      "[82]\ttraining's binary_logloss: 0.415849\tvalid_0's binary_logloss: 0.415979\n",
      "[83]\ttraining's binary_logloss: 0.415751\tvalid_0's binary_logloss: 0.415881\n",
      "[84]\ttraining's binary_logloss: 0.415609\tvalid_0's binary_logloss: 0.415749\n",
      "[85]\ttraining's binary_logloss: 0.415381\tvalid_0's binary_logloss: 0.415519\n",
      "[86]\ttraining's binary_logloss: 0.415287\tvalid_0's binary_logloss: 0.415451\n",
      "[87]\ttraining's binary_logloss: 0.415173\tvalid_0's binary_logloss: 0.415318\n",
      "[88]\ttraining's binary_logloss: 0.415048\tvalid_0's binary_logloss: 0.415196\n",
      "[89]\ttraining's binary_logloss: 0.414967\tvalid_0's binary_logloss: 0.415116\n",
      "[90]\ttraining's binary_logloss: 0.41486\tvalid_0's binary_logloss: 0.415018\n",
      "[91]\ttraining's binary_logloss: 0.414565\tvalid_0's binary_logloss: 0.414764\n",
      "[92]\ttraining's binary_logloss: 0.414442\tvalid_0's binary_logloss: 0.414642\n",
      "[93]\ttraining's binary_logloss: 0.414216\tvalid_0's binary_logloss: 0.414421\n",
      "[94]\ttraining's binary_logloss: 0.414159\tvalid_0's binary_logloss: 0.414357\n",
      "[95]\ttraining's binary_logloss: 0.413986\tvalid_0's binary_logloss: 0.414208\n",
      "[96]\ttraining's binary_logloss: 0.413901\tvalid_0's binary_logloss: 0.414172\n",
      "[97]\ttraining's binary_logloss: 0.413791\tvalid_0's binary_logloss: 0.414089\n",
      "[98]\ttraining's binary_logloss: 0.413735\tvalid_0's binary_logloss: 0.41403\n",
      "[99]\ttraining's binary_logloss: 0.413676\tvalid_0's binary_logloss: 0.413996\n",
      "[100]\ttraining's binary_logloss: 0.413589\tvalid_0's binary_logloss: 0.413892\n",
      "[101]\ttraining's binary_logloss: 0.413431\tvalid_0's binary_logloss: 0.41377\n",
      "[102]\ttraining's binary_logloss: 0.413245\tvalid_0's binary_logloss: 0.413576\n",
      "[103]\ttraining's binary_logloss: 0.41309\tvalid_0's binary_logloss: 0.413429\n",
      "[104]\ttraining's binary_logloss: 0.412991\tvalid_0's binary_logloss: 0.413303\n",
      "[105]\ttraining's binary_logloss: 0.412781\tvalid_0's binary_logloss: 0.413096\n",
      "[106]\ttraining's binary_logloss: 0.412675\tvalid_0's binary_logloss: 0.413027\n",
      "[107]\ttraining's binary_logloss: 0.412611\tvalid_0's binary_logloss: 0.412977\n",
      "[108]\ttraining's binary_logloss: 0.412545\tvalid_0's binary_logloss: 0.412914\n",
      "[109]\ttraining's binary_logloss: 0.412465\tvalid_0's binary_logloss: 0.412829\n",
      "[110]\ttraining's binary_logloss: 0.412398\tvalid_0's binary_logloss: 0.412772\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[111]\ttraining's binary_logloss: 0.412332\tvalid_0's binary_logloss: 0.412702\n",
      "[112]\ttraining's binary_logloss: 0.412271\tvalid_0's binary_logloss: 0.412656\n",
      "[113]\ttraining's binary_logloss: 0.4122\tvalid_0's binary_logloss: 0.41262\n",
      "[114]\ttraining's binary_logloss: 0.412129\tvalid_0's binary_logloss: 0.412545\n",
      "[115]\ttraining's binary_logloss: 0.41205\tvalid_0's binary_logloss: 0.412483\n",
      "[116]\ttraining's binary_logloss: 0.412\tvalid_0's binary_logloss: 0.412458\n",
      "[117]\ttraining's binary_logloss: 0.41196\tvalid_0's binary_logloss: 0.412421\n",
      "[118]\ttraining's binary_logloss: 0.411888\tvalid_0's binary_logloss: 0.412372\n",
      "[119]\ttraining's binary_logloss: 0.411836\tvalid_0's binary_logloss: 0.412316\n",
      "[120]\ttraining's binary_logloss: 0.411782\tvalid_0's binary_logloss: 0.412257\n",
      "[121]\ttraining's binary_logloss: 0.411658\tvalid_0's binary_logloss: 0.412138\n",
      "[122]\ttraining's binary_logloss: 0.411501\tvalid_0's binary_logloss: 0.412004\n",
      "[123]\ttraining's binary_logloss: 0.411459\tvalid_0's binary_logloss: 0.411981\n",
      "[124]\ttraining's binary_logloss: 0.411416\tvalid_0's binary_logloss: 0.411942\n",
      "[125]\ttraining's binary_logloss: 0.411301\tvalid_0's binary_logloss: 0.411806\n",
      "[126]\ttraining's binary_logloss: 0.411184\tvalid_0's binary_logloss: 0.411709\n",
      "[127]\ttraining's binary_logloss: 0.411146\tvalid_0's binary_logloss: 0.411676\n",
      "[128]\ttraining's binary_logloss: 0.411018\tvalid_0's binary_logloss: 0.411587\n",
      "[129]\ttraining's binary_logloss: 0.410899\tvalid_0's binary_logloss: 0.411471\n",
      "[130]\ttraining's binary_logloss: 0.41083\tvalid_0's binary_logloss: 0.411414\n",
      "[131]\ttraining's binary_logloss: 0.410782\tvalid_0's binary_logloss: 0.411357\n",
      "[132]\ttraining's binary_logloss: 0.410733\tvalid_0's binary_logloss: 0.411324\n",
      "[133]\ttraining's binary_logloss: 0.410697\tvalid_0's binary_logloss: 0.411292\n",
      "[134]\ttraining's binary_logloss: 0.410656\tvalid_0's binary_logloss: 0.411245\n",
      "[135]\ttraining's binary_logloss: 0.410614\tvalid_0's binary_logloss: 0.411183\n",
      "[136]\ttraining's binary_logloss: 0.410559\tvalid_0's binary_logloss: 0.411127\n",
      "[137]\ttraining's binary_logloss: 0.410468\tvalid_0's binary_logloss: 0.411032\n",
      "[138]\ttraining's binary_logloss: 0.410403\tvalid_0's binary_logloss: 0.410994\n",
      "[139]\ttraining's binary_logloss: 0.410366\tvalid_0's binary_logloss: 0.410974\n",
      "[140]\ttraining's binary_logloss: 0.410315\tvalid_0's binary_logloss: 0.410957\n",
      "[141]\ttraining's binary_logloss: 0.410162\tvalid_0's binary_logloss: 0.410821\n",
      "[142]\ttraining's binary_logloss: 0.410122\tvalid_0's binary_logloss: 0.410785\n",
      "[143]\ttraining's binary_logloss: 0.410041\tvalid_0's binary_logloss: 0.410752\n",
      "[144]\ttraining's binary_logloss: 0.409962\tvalid_0's binary_logloss: 0.410701\n",
      "[145]\ttraining's binary_logloss: 0.409937\tvalid_0's binary_logloss: 0.410671\n",
      "[146]\ttraining's binary_logloss: 0.409887\tvalid_0's binary_logloss: 0.41063\n",
      "[147]\ttraining's binary_logloss: 0.409846\tvalid_0's binary_logloss: 0.410573\n",
      "[148]\ttraining's binary_logloss: 0.409815\tvalid_0's binary_logloss: 0.410554\n",
      "[149]\ttraining's binary_logloss: 0.409784\tvalid_0's binary_logloss: 0.410538\n",
      "[150]\ttraining's binary_logloss: 0.409753\tvalid_0's binary_logloss: 0.41053\n",
      "[151]\ttraining's binary_logloss: 0.409716\tvalid_0's binary_logloss: 0.410484\n",
      "[152]\ttraining's binary_logloss: 0.409629\tvalid_0's binary_logloss: 0.410397\n",
      "[153]\ttraining's binary_logloss: 0.409564\tvalid_0's binary_logloss: 0.410347\n",
      "[154]\ttraining's binary_logloss: 0.409531\tvalid_0's binary_logloss: 0.41032\n",
      "[155]\ttraining's binary_logloss: 0.409429\tvalid_0's binary_logloss: 0.410231\n",
      "[156]\ttraining's binary_logloss: 0.409393\tvalid_0's binary_logloss: 0.410206\n",
      "[157]\ttraining's binary_logloss: 0.409361\tvalid_0's binary_logloss: 0.410176\n",
      "[158]\ttraining's binary_logloss: 0.409337\tvalid_0's binary_logloss: 0.41019\n",
      "[159]\ttraining's binary_logloss: 0.409125\tvalid_0's binary_logloss: 0.409986\n",
      "[160]\ttraining's binary_logloss: 0.409102\tvalid_0's binary_logloss: 0.409985\n",
      "[161]\ttraining's binary_logloss: 0.409058\tvalid_0's binary_logloss: 0.409944\n",
      "[162]\ttraining's binary_logloss: 0.408964\tvalid_0's binary_logloss: 0.409876\n",
      "[163]\ttraining's binary_logloss: 0.408892\tvalid_0's binary_logloss: 0.409821\n",
      "[164]\ttraining's binary_logloss: 0.408857\tvalid_0's binary_logloss: 0.409801\n",
      "[165]\ttraining's binary_logloss: 0.408831\tvalid_0's binary_logloss: 0.409779\n",
      "[166]\ttraining's binary_logloss: 0.408805\tvalid_0's binary_logloss: 0.409766\n",
      "[167]\ttraining's binary_logloss: 0.408769\tvalid_0's binary_logloss: 0.40975\n",
      "[168]\ttraining's binary_logloss: 0.408584\tvalid_0's binary_logloss: 0.409591\n",
      "[169]\ttraining's binary_logloss: 0.408431\tvalid_0's binary_logloss: 0.409486\n",
      "[170]\ttraining's binary_logloss: 0.408367\tvalid_0's binary_logloss: 0.409416\n",
      "[171]\ttraining's binary_logloss: 0.408212\tvalid_0's binary_logloss: 0.409312\n",
      "[172]\ttraining's binary_logloss: 0.408185\tvalid_0's binary_logloss: 0.409285\n",
      "[173]\ttraining's binary_logloss: 0.408145\tvalid_0's binary_logloss: 0.409256\n",
      "[174]\ttraining's binary_logloss: 0.408119\tvalid_0's binary_logloss: 0.409236\n",
      "[175]\ttraining's binary_logloss: 0.408075\tvalid_0's binary_logloss: 0.409214\n",
      "[176]\ttraining's binary_logloss: 0.408055\tvalid_0's binary_logloss: 0.40921\n",
      "[177]\ttraining's binary_logloss: 0.408004\tvalid_0's binary_logloss: 0.409177\n",
      "[178]\ttraining's binary_logloss: 0.407937\tvalid_0's binary_logloss: 0.409134\n",
      "[179]\ttraining's binary_logloss: 0.407809\tvalid_0's binary_logloss: 0.409014\n",
      "[180]\ttraining's binary_logloss: 0.407787\tvalid_0's binary_logloss: 0.408984\n",
      "[181]\ttraining's binary_logloss: 0.407759\tvalid_0's binary_logloss: 0.408972\n",
      "[182]\ttraining's binary_logloss: 0.407693\tvalid_0's binary_logloss: 0.408926\n",
      "[183]\ttraining's binary_logloss: 0.407666\tvalid_0's binary_logloss: 0.408922\n",
      "[184]\ttraining's binary_logloss: 0.407643\tvalid_0's binary_logloss: 0.408896\n",
      "[185]\ttraining's binary_logloss: 0.407614\tvalid_0's binary_logloss: 0.408874\n",
      "[186]\ttraining's binary_logloss: 0.40759\tvalid_0's binary_logloss: 0.408867\n",
      "[187]\ttraining's binary_logloss: 0.407558\tvalid_0's binary_logloss: 0.408834\n",
      "[188]\ttraining's binary_logloss: 0.407521\tvalid_0's binary_logloss: 0.408808\n",
      "[189]\ttraining's binary_logloss: 0.407498\tvalid_0's binary_logloss: 0.408805\n",
      "[190]\ttraining's binary_logloss: 0.407381\tvalid_0's binary_logloss: 0.408707\n",
      "[191]\ttraining's binary_logloss: 0.407356\tvalid_0's binary_logloss: 0.408683\n",
      "[192]\ttraining's binary_logloss: 0.407286\tvalid_0's binary_logloss: 0.408614\n",
      "[193]\ttraining's binary_logloss: 0.407253\tvalid_0's binary_logloss: 0.408613\n",
      "[194]\ttraining's binary_logloss: 0.407231\tvalid_0's binary_logloss: 0.408607\n",
      "[195]\ttraining's binary_logloss: 0.407208\tvalid_0's binary_logloss: 0.408585\n",
      "[196]\ttraining's binary_logloss: 0.40711\tvalid_0's binary_logloss: 0.408477\n",
      "[197]\ttraining's binary_logloss: 0.407087\tvalid_0's binary_logloss: 0.408465\n",
      "[198]\ttraining's binary_logloss: 0.407063\tvalid_0's binary_logloss: 0.408456\n",
      "[199]\ttraining's binary_logloss: 0.407043\tvalid_0's binary_logloss: 0.408457\n",
      "[200]\ttraining's binary_logloss: 0.406923\tvalid_0's binary_logloss: 0.408343\n",
      "[201]\ttraining's binary_logloss: 0.406905\tvalid_0's binary_logloss: 0.408346\n",
      "[202]\ttraining's binary_logloss: 0.406876\tvalid_0's binary_logloss: 0.408332\n",
      "[203]\ttraining's binary_logloss: 0.406788\tvalid_0's binary_logloss: 0.40825\n",
      "[204]\ttraining's binary_logloss: 0.406766\tvalid_0's binary_logloss: 0.408248\n",
      "[205]\ttraining's binary_logloss: 0.406658\tvalid_0's binary_logloss: 0.408154\n",
      "[206]\ttraining's binary_logloss: 0.406631\tvalid_0's binary_logloss: 0.408144\n",
      "[207]\ttraining's binary_logloss: 0.406605\tvalid_0's binary_logloss: 0.408129\n",
      "[208]\ttraining's binary_logloss: 0.406587\tvalid_0's binary_logloss: 0.408134\n",
      "[209]\ttraining's binary_logloss: 0.4065\tvalid_0's binary_logloss: 0.408065\n",
      "[210]\ttraining's binary_logloss: 0.406483\tvalid_0's binary_logloss: 0.408054\n",
      "[211]\ttraining's binary_logloss: 0.40646\tvalid_0's binary_logloss: 0.408044\n",
      "[212]\ttraining's binary_logloss: 0.406412\tvalid_0's binary_logloss: 0.407981\n",
      "[213]\ttraining's binary_logloss: 0.406393\tvalid_0's binary_logloss: 0.407971\n",
      "[214]\ttraining's binary_logloss: 0.406378\tvalid_0's binary_logloss: 0.407967\n",
      "[215]\ttraining's binary_logloss: 0.406343\tvalid_0's binary_logloss: 0.407955\n",
      "[216]\ttraining's binary_logloss: 0.406279\tvalid_0's binary_logloss: 0.407901\n",
      "[217]\ttraining's binary_logloss: 0.40612\tvalid_0's binary_logloss: 0.407758\n",
      "[218]\ttraining's binary_logloss: 0.406031\tvalid_0's binary_logloss: 0.407675\n",
      "[219]\ttraining's binary_logloss: 0.405996\tvalid_0's binary_logloss: 0.40763\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[220]\ttraining's binary_logloss: 0.405974\tvalid_0's binary_logloss: 0.407616\n",
      "[221]\ttraining's binary_logloss: 0.405936\tvalid_0's binary_logloss: 0.407598\n",
      "[222]\ttraining's binary_logloss: 0.4059\tvalid_0's binary_logloss: 0.407584\n",
      "[223]\ttraining's binary_logloss: 0.405871\tvalid_0's binary_logloss: 0.407567\n",
      "[224]\ttraining's binary_logloss: 0.405851\tvalid_0's binary_logloss: 0.407562\n",
      "[225]\ttraining's binary_logloss: 0.405835\tvalid_0's binary_logloss: 0.407559\n",
      "[226]\ttraining's binary_logloss: 0.405807\tvalid_0's binary_logloss: 0.407554\n",
      "[227]\ttraining's binary_logloss: 0.405789\tvalid_0's binary_logloss: 0.407557\n",
      "[228]\ttraining's binary_logloss: 0.405773\tvalid_0's binary_logloss: 0.407562\n",
      "[229]\ttraining's binary_logloss: 0.405704\tvalid_0's binary_logloss: 0.407536\n",
      "[230]\ttraining's binary_logloss: 0.40568\tvalid_0's binary_logloss: 0.407522\n",
      "[231]\ttraining's binary_logloss: 0.405659\tvalid_0's binary_logloss: 0.407513\n",
      "[232]\ttraining's binary_logloss: 0.405582\tvalid_0's binary_logloss: 0.407436\n",
      "[233]\ttraining's binary_logloss: 0.405551\tvalid_0's binary_logloss: 0.407418\n",
      "[234]\ttraining's binary_logloss: 0.405531\tvalid_0's binary_logloss: 0.407422\n",
      "[235]\ttraining's binary_logloss: 0.405512\tvalid_0's binary_logloss: 0.407422\n",
      "[236]\ttraining's binary_logloss: 0.405486\tvalid_0's binary_logloss: 0.407409\n",
      "[237]\ttraining's binary_logloss: 0.405465\tvalid_0's binary_logloss: 0.407412\n",
      "[238]\ttraining's binary_logloss: 0.405445\tvalid_0's binary_logloss: 0.407402\n",
      "[239]\ttraining's binary_logloss: 0.405415\tvalid_0's binary_logloss: 0.407383\n",
      "[240]\ttraining's binary_logloss: 0.405399\tvalid_0's binary_logloss: 0.407377\n",
      "[241]\ttraining's binary_logloss: 0.405375\tvalid_0's binary_logloss: 0.407372\n",
      "[242]\ttraining's binary_logloss: 0.40535\tvalid_0's binary_logloss: 0.407365\n",
      "[243]\ttraining's binary_logloss: 0.405317\tvalid_0's binary_logloss: 0.407332\n",
      "[244]\ttraining's binary_logloss: 0.405294\tvalid_0's binary_logloss: 0.407332\n",
      "[245]\ttraining's binary_logloss: 0.405272\tvalid_0's binary_logloss: 0.407333\n",
      "[246]\ttraining's binary_logloss: 0.405253\tvalid_0's binary_logloss: 0.407344\n",
      "[247]\ttraining's binary_logloss: 0.405238\tvalid_0's binary_logloss: 0.407344\n",
      "[248]\ttraining's binary_logloss: 0.405218\tvalid_0's binary_logloss: 0.407337\n",
      "[249]\ttraining's binary_logloss: 0.405202\tvalid_0's binary_logloss: 0.407329\n",
      "[250]\ttraining's binary_logloss: 0.405181\tvalid_0's binary_logloss: 0.407329\n",
      "[251]\ttraining's binary_logloss: 0.40516\tvalid_0's binary_logloss: 0.407331\n",
      "[252]\ttraining's binary_logloss: 0.405144\tvalid_0's binary_logloss: 0.407317\n",
      "[253]\ttraining's binary_logloss: 0.405107\tvalid_0's binary_logloss: 0.407284\n",
      "[254]\ttraining's binary_logloss: 0.405082\tvalid_0's binary_logloss: 0.407246\n",
      "[255]\ttraining's binary_logloss: 0.405067\tvalid_0's binary_logloss: 0.407237\n",
      "[256]\ttraining's binary_logloss: 0.404938\tvalid_0's binary_logloss: 0.407128\n",
      "[257]\ttraining's binary_logloss: 0.404861\tvalid_0's binary_logloss: 0.40706\n",
      "[258]\ttraining's binary_logloss: 0.404846\tvalid_0's binary_logloss: 0.407061\n",
      "[259]\ttraining's binary_logloss: 0.404827\tvalid_0's binary_logloss: 0.407046\n",
      "[260]\ttraining's binary_logloss: 0.404743\tvalid_0's binary_logloss: 0.40695\n",
      "[261]\ttraining's binary_logloss: 0.404594\tvalid_0's binary_logloss: 0.406831\n",
      "[262]\ttraining's binary_logloss: 0.404492\tvalid_0's binary_logloss: 0.406768\n",
      "[263]\ttraining's binary_logloss: 0.40447\tvalid_0's binary_logloss: 0.406775\n",
      "[264]\ttraining's binary_logloss: 0.40445\tvalid_0's binary_logloss: 0.406771\n",
      "[265]\ttraining's binary_logloss: 0.404428\tvalid_0's binary_logloss: 0.406771\n",
      "[266]\ttraining's binary_logloss: 0.404349\tvalid_0's binary_logloss: 0.406706\n",
      "[267]\ttraining's binary_logloss: 0.404322\tvalid_0's binary_logloss: 0.406666\n",
      "[268]\ttraining's binary_logloss: 0.404307\tvalid_0's binary_logloss: 0.406669\n",
      "[269]\ttraining's binary_logloss: 0.404288\tvalid_0's binary_logloss: 0.406676\n",
      "[270]\ttraining's binary_logloss: 0.404196\tvalid_0's binary_logloss: 0.406591\n",
      "[271]\ttraining's binary_logloss: 0.404177\tvalid_0's binary_logloss: 0.406587\n",
      "[272]\ttraining's binary_logloss: 0.404154\tvalid_0's binary_logloss: 0.406586\n",
      "[273]\ttraining's binary_logloss: 0.404139\tvalid_0's binary_logloss: 0.406588\n",
      "[274]\ttraining's binary_logloss: 0.404123\tvalid_0's binary_logloss: 0.406603\n",
      "[275]\ttraining's binary_logloss: 0.404106\tvalid_0's binary_logloss: 0.406607\n",
      "[276]\ttraining's binary_logloss: 0.404091\tvalid_0's binary_logloss: 0.406614\n",
      "[277]\ttraining's binary_logloss: 0.404074\tvalid_0's binary_logloss: 0.406607\n",
      "[278]\ttraining's binary_logloss: 0.403988\tvalid_0's binary_logloss: 0.406537\n",
      "[279]\ttraining's binary_logloss: 0.40396\tvalid_0's binary_logloss: 0.406519\n",
      "[280]\ttraining's binary_logloss: 0.403945\tvalid_0's binary_logloss: 0.40651\n",
      "[281]\ttraining's binary_logloss: 0.403896\tvalid_0's binary_logloss: 0.406469\n",
      "[282]\ttraining's binary_logloss: 0.403828\tvalid_0's binary_logloss: 0.406407\n",
      "[283]\ttraining's binary_logloss: 0.403806\tvalid_0's binary_logloss: 0.40639\n",
      "[284]\ttraining's binary_logloss: 0.40379\tvalid_0's binary_logloss: 0.406414\n",
      "[285]\ttraining's binary_logloss: 0.403769\tvalid_0's binary_logloss: 0.40641\n",
      "[286]\ttraining's binary_logloss: 0.403746\tvalid_0's binary_logloss: 0.40638\n",
      "[287]\ttraining's binary_logloss: 0.403714\tvalid_0's binary_logloss: 0.406385\n",
      "[288]\ttraining's binary_logloss: 0.403696\tvalid_0's binary_logloss: 0.406371\n",
      "[289]\ttraining's binary_logloss: 0.40368\tvalid_0's binary_logloss: 0.406375\n",
      "[290]\ttraining's binary_logloss: 0.403663\tvalid_0's binary_logloss: 0.406369\n",
      "[291]\ttraining's binary_logloss: 0.403647\tvalid_0's binary_logloss: 0.406357\n",
      "[292]\ttraining's binary_logloss: 0.403581\tvalid_0's binary_logloss: 0.406286\n",
      "[293]\ttraining's binary_logloss: 0.403566\tvalid_0's binary_logloss: 0.406288\n",
      "[294]\ttraining's binary_logloss: 0.403545\tvalid_0's binary_logloss: 0.406298\n",
      "[295]\ttraining's binary_logloss: 0.403527\tvalid_0's binary_logloss: 0.406298\n",
      "[296]\ttraining's binary_logloss: 0.403507\tvalid_0's binary_logloss: 0.406279\n",
      "[297]\ttraining's binary_logloss: 0.403485\tvalid_0's binary_logloss: 0.406259\n",
      "[298]\ttraining's binary_logloss: 0.403465\tvalid_0's binary_logloss: 0.406264\n",
      "[299]\ttraining's binary_logloss: 0.403395\tvalid_0's binary_logloss: 0.406226\n",
      "[300]\ttraining's binary_logloss: 0.40338\tvalid_0's binary_logloss: 0.406227\n",
      "[301]\ttraining's binary_logloss: 0.403364\tvalid_0's binary_logloss: 0.406231\n",
      "[302]\ttraining's binary_logloss: 0.403343\tvalid_0's binary_logloss: 0.406211\n",
      "[303]\ttraining's binary_logloss: 0.403324\tvalid_0's binary_logloss: 0.406217\n",
      "[304]\ttraining's binary_logloss: 0.403306\tvalid_0's binary_logloss: 0.406212\n",
      "[305]\ttraining's binary_logloss: 0.403257\tvalid_0's binary_logloss: 0.406167\n",
      "[306]\ttraining's binary_logloss: 0.403232\tvalid_0's binary_logloss: 0.406153\n",
      "[307]\ttraining's binary_logloss: 0.403213\tvalid_0's binary_logloss: 0.406161\n",
      "[308]\ttraining's binary_logloss: 0.403194\tvalid_0's binary_logloss: 0.406137\n",
      "[309]\ttraining's binary_logloss: 0.403178\tvalid_0's binary_logloss: 0.406137\n",
      "[310]\ttraining's binary_logloss: 0.40316\tvalid_0's binary_logloss: 0.406143\n",
      "[311]\ttraining's binary_logloss: 0.403057\tvalid_0's binary_logloss: 0.406043\n",
      "[312]\ttraining's binary_logloss: 0.403008\tvalid_0's binary_logloss: 0.405995\n",
      "[313]\ttraining's binary_logloss: 0.402986\tvalid_0's binary_logloss: 0.405988\n",
      "[314]\ttraining's binary_logloss: 0.402969\tvalid_0's binary_logloss: 0.405992\n",
      "[315]\ttraining's binary_logloss: 0.402953\tvalid_0's binary_logloss: 0.405988\n",
      "[316]\ttraining's binary_logloss: 0.402896\tvalid_0's binary_logloss: 0.405941\n",
      "[317]\ttraining's binary_logloss: 0.402879\tvalid_0's binary_logloss: 0.405938\n",
      "[318]\ttraining's binary_logloss: 0.402857\tvalid_0's binary_logloss: 0.405923\n",
      "[319]\ttraining's binary_logloss: 0.402788\tvalid_0's binary_logloss: 0.405848\n",
      "[320]\ttraining's binary_logloss: 0.40275\tvalid_0's binary_logloss: 0.405815\n",
      "[321]\ttraining's binary_logloss: 0.402729\tvalid_0's binary_logloss: 0.40582\n",
      "[322]\ttraining's binary_logloss: 0.402712\tvalid_0's binary_logloss: 0.405844\n",
      "[323]\ttraining's binary_logloss: 0.40269\tvalid_0's binary_logloss: 0.405828\n",
      "[324]\ttraining's binary_logloss: 0.402666\tvalid_0's binary_logloss: 0.405837\n",
      "[325]\ttraining's binary_logloss: 0.40261\tvalid_0's binary_logloss: 0.405781\n",
      "[326]\ttraining's binary_logloss: 0.402567\tvalid_0's binary_logloss: 0.405766\n",
      "[327]\ttraining's binary_logloss: 0.402537\tvalid_0's binary_logloss: 0.405736\n",
      "[328]\ttraining's binary_logloss: 0.402515\tvalid_0's binary_logloss: 0.405729\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[329]\ttraining's binary_logloss: 0.402496\tvalid_0's binary_logloss: 0.405734\n",
      "[330]\ttraining's binary_logloss: 0.402427\tvalid_0's binary_logloss: 0.405674\n",
      "[331]\ttraining's binary_logloss: 0.402407\tvalid_0's binary_logloss: 0.405691\n",
      "[332]\ttraining's binary_logloss: 0.402386\tvalid_0's binary_logloss: 0.405686\n",
      "[333]\ttraining's binary_logloss: 0.402372\tvalid_0's binary_logloss: 0.405698\n",
      "[334]\ttraining's binary_logloss: 0.402345\tvalid_0's binary_logloss: 0.405693\n",
      "[335]\ttraining's binary_logloss: 0.402332\tvalid_0's binary_logloss: 0.405693\n",
      "[336]\ttraining's binary_logloss: 0.402308\tvalid_0's binary_logloss: 0.405699\n",
      "[337]\ttraining's binary_logloss: 0.402278\tvalid_0's binary_logloss: 0.405684\n",
      "[338]\ttraining's binary_logloss: 0.402264\tvalid_0's binary_logloss: 0.405687\n",
      "[339]\ttraining's binary_logloss: 0.402244\tvalid_0's binary_logloss: 0.405695\n",
      "[340]\ttraining's binary_logloss: 0.402204\tvalid_0's binary_logloss: 0.405668\n",
      "[341]\ttraining's binary_logloss: 0.402191\tvalid_0's binary_logloss: 0.405663\n",
      "[342]\ttraining's binary_logloss: 0.402173\tvalid_0's binary_logloss: 0.405657\n",
      "[343]\ttraining's binary_logloss: 0.402159\tvalid_0's binary_logloss: 0.405657\n",
      "[344]\ttraining's binary_logloss: 0.402144\tvalid_0's binary_logloss: 0.405651\n",
      "[345]\ttraining's binary_logloss: 0.402122\tvalid_0's binary_logloss: 0.40564\n",
      "[346]\ttraining's binary_logloss: 0.402102\tvalid_0's binary_logloss: 0.40561\n",
      "[347]\ttraining's binary_logloss: 0.402054\tvalid_0's binary_logloss: 0.405567\n",
      "[348]\ttraining's binary_logloss: 0.401996\tvalid_0's binary_logloss: 0.405521\n",
      "[349]\ttraining's binary_logloss: 0.40198\tvalid_0's binary_logloss: 0.405527\n",
      "[350]\ttraining's binary_logloss: 0.401963\tvalid_0's binary_logloss: 0.405516\n",
      "[351]\ttraining's binary_logloss: 0.401944\tvalid_0's binary_logloss: 0.405526\n",
      "[352]\ttraining's binary_logloss: 0.401908\tvalid_0's binary_logloss: 0.405481\n",
      "[353]\ttraining's binary_logloss: 0.401886\tvalid_0's binary_logloss: 0.405485\n",
      "[354]\ttraining's binary_logloss: 0.401873\tvalid_0's binary_logloss: 0.4055\n",
      "[355]\ttraining's binary_logloss: 0.401859\tvalid_0's binary_logloss: 0.405494\n",
      "[356]\ttraining's binary_logloss: 0.401824\tvalid_0's binary_logloss: 0.405475\n",
      "[357]\ttraining's binary_logloss: 0.401803\tvalid_0's binary_logloss: 0.405487\n",
      "[358]\ttraining's binary_logloss: 0.401775\tvalid_0's binary_logloss: 0.405457\n",
      "[359]\ttraining's binary_logloss: 0.401763\tvalid_0's binary_logloss: 0.405464\n",
      "[360]\ttraining's binary_logloss: 0.401752\tvalid_0's binary_logloss: 0.405463\n",
      "[361]\ttraining's binary_logloss: 0.401736\tvalid_0's binary_logloss: 0.405469\n",
      "[362]\ttraining's binary_logloss: 0.401717\tvalid_0's binary_logloss: 0.405481\n",
      "[363]\ttraining's binary_logloss: 0.401698\tvalid_0's binary_logloss: 0.405474\n",
      "[364]\ttraining's binary_logloss: 0.401686\tvalid_0's binary_logloss: 0.405485\n",
      "[365]\ttraining's binary_logloss: 0.401669\tvalid_0's binary_logloss: 0.405485\n",
      "[366]\ttraining's binary_logloss: 0.401654\tvalid_0's binary_logloss: 0.405487\n",
      "[367]\ttraining's binary_logloss: 0.401643\tvalid_0's binary_logloss: 0.405494\n",
      "[368]\ttraining's binary_logloss: 0.401578\tvalid_0's binary_logloss: 0.405443\n",
      "[369]\ttraining's binary_logloss: 0.401518\tvalid_0's binary_logloss: 0.40538\n",
      "[370]\ttraining's binary_logloss: 0.401502\tvalid_0's binary_logloss: 0.405373\n",
      "[371]\ttraining's binary_logloss: 0.401484\tvalid_0's binary_logloss: 0.40539\n",
      "[372]\ttraining's binary_logloss: 0.401469\tvalid_0's binary_logloss: 0.405404\n",
      "[373]\ttraining's binary_logloss: 0.401454\tvalid_0's binary_logloss: 0.405404\n",
      "[374]\ttraining's binary_logloss: 0.401437\tvalid_0's binary_logloss: 0.405404\n",
      "[375]\ttraining's binary_logloss: 0.401417\tvalid_0's binary_logloss: 0.405407\n",
      "[376]\ttraining's binary_logloss: 0.401403\tvalid_0's binary_logloss: 0.405425\n",
      "[377]\ttraining's binary_logloss: 0.401354\tvalid_0's binary_logloss: 0.405369\n",
      "[378]\ttraining's binary_logloss: 0.401326\tvalid_0's binary_logloss: 0.405351\n",
      "[379]\ttraining's binary_logloss: 0.401312\tvalid_0's binary_logloss: 0.405352\n",
      "[380]\ttraining's binary_logloss: 0.401295\tvalid_0's binary_logloss: 0.405364\n",
      "[381]\ttraining's binary_logloss: 0.401279\tvalid_0's binary_logloss: 0.405394\n",
      "[382]\ttraining's binary_logloss: 0.401265\tvalid_0's binary_logloss: 0.405396\n",
      "[383]\ttraining's binary_logloss: 0.401215\tvalid_0's binary_logloss: 0.405357\n",
      "[384]\ttraining's binary_logloss: 0.40117\tvalid_0's binary_logloss: 0.405334\n",
      "[385]\ttraining's binary_logloss: 0.401158\tvalid_0's binary_logloss: 0.405324\n",
      "[386]\ttraining's binary_logloss: 0.401123\tvalid_0's binary_logloss: 0.4053\n",
      "[387]\ttraining's binary_logloss: 0.40111\tvalid_0's binary_logloss: 0.405311\n",
      "[388]\ttraining's binary_logloss: 0.401043\tvalid_0's binary_logloss: 0.405294\n",
      "[389]\ttraining's binary_logloss: 0.401023\tvalid_0's binary_logloss: 0.405301\n",
      "[390]\ttraining's binary_logloss: 0.401007\tvalid_0's binary_logloss: 0.405308\n",
      "[391]\ttraining's binary_logloss: 0.400975\tvalid_0's binary_logloss: 0.405266\n",
      "[392]\ttraining's binary_logloss: 0.400957\tvalid_0's binary_logloss: 0.405269\n",
      "[393]\ttraining's binary_logloss: 0.400942\tvalid_0's binary_logloss: 0.405266\n",
      "[394]\ttraining's binary_logloss: 0.40092\tvalid_0's binary_logloss: 0.40525\n",
      "[395]\ttraining's binary_logloss: 0.400903\tvalid_0's binary_logloss: 0.405262\n",
      "[396]\ttraining's binary_logloss: 0.400858\tvalid_0's binary_logloss: 0.405225\n",
      "[397]\ttraining's binary_logloss: 0.400842\tvalid_0's binary_logloss: 0.405223\n",
      "[398]\ttraining's binary_logloss: 0.400828\tvalid_0's binary_logloss: 0.405245\n",
      "[399]\ttraining's binary_logloss: 0.400816\tvalid_0's binary_logloss: 0.40524\n",
      "[400]\ttraining's binary_logloss: 0.400802\tvalid_0's binary_logloss: 0.405235\n",
      "[401]\ttraining's binary_logloss: 0.400786\tvalid_0's binary_logloss: 0.405241\n",
      "[402]\ttraining's binary_logloss: 0.400767\tvalid_0's binary_logloss: 0.405231\n",
      "[403]\ttraining's binary_logloss: 0.40075\tvalid_0's binary_logloss: 0.405238\n",
      "[404]\ttraining's binary_logloss: 0.400736\tvalid_0's binary_logloss: 0.405233\n",
      "[405]\ttraining's binary_logloss: 0.40072\tvalid_0's binary_logloss: 0.405224\n",
      "[406]\ttraining's binary_logloss: 0.400702\tvalid_0's binary_logloss: 0.405221\n",
      "[407]\ttraining's binary_logloss: 0.400683\tvalid_0's binary_logloss: 0.405219\n",
      "[408]\ttraining's binary_logloss: 0.400668\tvalid_0's binary_logloss: 0.405224\n",
      "[409]\ttraining's binary_logloss: 0.400653\tvalid_0's binary_logloss: 0.405219\n",
      "[410]\ttraining's binary_logloss: 0.400633\tvalid_0's binary_logloss: 0.405206\n",
      "[411]\ttraining's binary_logloss: 0.400583\tvalid_0's binary_logloss: 0.40515\n",
      "[412]\ttraining's binary_logloss: 0.400564\tvalid_0's binary_logloss: 0.405142\n",
      "[413]\ttraining's binary_logloss: 0.40054\tvalid_0's binary_logloss: 0.405118\n",
      "[414]\ttraining's binary_logloss: 0.400485\tvalid_0's binary_logloss: 0.40509\n",
      "[415]\ttraining's binary_logloss: 0.400471\tvalid_0's binary_logloss: 0.405089\n",
      "[416]\ttraining's binary_logloss: 0.400422\tvalid_0's binary_logloss: 0.405057\n",
      "[417]\ttraining's binary_logloss: 0.400364\tvalid_0's binary_logloss: 0.404997\n",
      "[418]\ttraining's binary_logloss: 0.40035\tvalid_0's binary_logloss: 0.404991\n",
      "[419]\ttraining's binary_logloss: 0.400331\tvalid_0's binary_logloss: 0.405008\n",
      "[420]\ttraining's binary_logloss: 0.400301\tvalid_0's binary_logloss: 0.404973\n",
      "[421]\ttraining's binary_logloss: 0.400274\tvalid_0's binary_logloss: 0.404953\n",
      "[422]\ttraining's binary_logloss: 0.400264\tvalid_0's binary_logloss: 0.404953\n",
      "[423]\ttraining's binary_logloss: 0.40025\tvalid_0's binary_logloss: 0.404951\n",
      "[424]\ttraining's binary_logloss: 0.400232\tvalid_0's binary_logloss: 0.40497\n",
      "[425]\ttraining's binary_logloss: 0.400212\tvalid_0's binary_logloss: 0.404965\n",
      "[426]\ttraining's binary_logloss: 0.400194\tvalid_0's binary_logloss: 0.404951\n",
      "[427]\ttraining's binary_logloss: 0.400141\tvalid_0's binary_logloss: 0.404906\n",
      "[428]\ttraining's binary_logloss: 0.400128\tvalid_0's binary_logloss: 0.404896\n",
      "[429]\ttraining's binary_logloss: 0.400108\tvalid_0's binary_logloss: 0.404883\n",
      "[430]\ttraining's binary_logloss: 0.400092\tvalid_0's binary_logloss: 0.404878\n",
      "[431]\ttraining's binary_logloss: 0.400079\tvalid_0's binary_logloss: 0.404881\n",
      "[432]\ttraining's binary_logloss: 0.40006\tvalid_0's binary_logloss: 0.404862\n",
      "[433]\ttraining's binary_logloss: 0.400046\tvalid_0's binary_logloss: 0.404865\n",
      "[434]\ttraining's binary_logloss: 0.400034\tvalid_0's binary_logloss: 0.404864\n",
      "[435]\ttraining's binary_logloss: 0.400012\tvalid_0's binary_logloss: 0.404856\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[436]\ttraining's binary_logloss: 0.399994\tvalid_0's binary_logloss: 0.404847\n",
      "[437]\ttraining's binary_logloss: 0.399969\tvalid_0's binary_logloss: 0.404845\n",
      "[438]\ttraining's binary_logloss: 0.399951\tvalid_0's binary_logloss: 0.404842\n",
      "[439]\ttraining's binary_logloss: 0.399938\tvalid_0's binary_logloss: 0.40485\n",
      "[440]\ttraining's binary_logloss: 0.399921\tvalid_0's binary_logloss: 0.404852\n",
      "[441]\ttraining's binary_logloss: 0.399883\tvalid_0's binary_logloss: 0.404808\n",
      "[442]\ttraining's binary_logloss: 0.399864\tvalid_0's binary_logloss: 0.404793\n",
      "[443]\ttraining's binary_logloss: 0.399841\tvalid_0's binary_logloss: 0.404789\n",
      "[444]\ttraining's binary_logloss: 0.399818\tvalid_0's binary_logloss: 0.40478\n",
      "[445]\ttraining's binary_logloss: 0.399787\tvalid_0's binary_logloss: 0.40475\n",
      "[446]\ttraining's binary_logloss: 0.399771\tvalid_0's binary_logloss: 0.404745\n",
      "[447]\ttraining's binary_logloss: 0.399756\tvalid_0's binary_logloss: 0.404727\n",
      "[448]\ttraining's binary_logloss: 0.399725\tvalid_0's binary_logloss: 0.404715\n",
      "[449]\ttraining's binary_logloss: 0.399701\tvalid_0's binary_logloss: 0.404724\n",
      "[450]\ttraining's binary_logloss: 0.39964\tvalid_0's binary_logloss: 0.404683\n",
      "[451]\ttraining's binary_logloss: 0.399621\tvalid_0's binary_logloss: 0.404666\n",
      "[452]\ttraining's binary_logloss: 0.399601\tvalid_0's binary_logloss: 0.404644\n",
      "[453]\ttraining's binary_logloss: 0.399577\tvalid_0's binary_logloss: 0.404636\n",
      "[454]\ttraining's binary_logloss: 0.399558\tvalid_0's binary_logloss: 0.404641\n",
      "[455]\ttraining's binary_logloss: 0.39954\tvalid_0's binary_logloss: 0.404649\n",
      "[456]\ttraining's binary_logloss: 0.399525\tvalid_0's binary_logloss: 0.404648\n",
      "[457]\ttraining's binary_logloss: 0.399509\tvalid_0's binary_logloss: 0.404643\n",
      "[458]\ttraining's binary_logloss: 0.399493\tvalid_0's binary_logloss: 0.404645\n",
      "[459]\ttraining's binary_logloss: 0.399469\tvalid_0's binary_logloss: 0.404649\n",
      "[460]\ttraining's binary_logloss: 0.399454\tvalid_0's binary_logloss: 0.404659\n",
      "[461]\ttraining's binary_logloss: 0.399439\tvalid_0's binary_logloss: 0.404656\n",
      "[462]\ttraining's binary_logloss: 0.399404\tvalid_0's binary_logloss: 0.40464\n",
      "[463]\ttraining's binary_logloss: 0.39939\tvalid_0's binary_logloss: 0.404644\n",
      "[464]\ttraining's binary_logloss: 0.399353\tvalid_0's binary_logloss: 0.404621\n",
      "[465]\ttraining's binary_logloss: 0.399339\tvalid_0's binary_logloss: 0.40462\n",
      "[466]\ttraining's binary_logloss: 0.399313\tvalid_0's binary_logloss: 0.404609\n",
      "[467]\ttraining's binary_logloss: 0.399298\tvalid_0's binary_logloss: 0.404608\n",
      "[468]\ttraining's binary_logloss: 0.399287\tvalid_0's binary_logloss: 0.404603\n",
      "[469]\ttraining's binary_logloss: 0.399273\tvalid_0's binary_logloss: 0.404611\n",
      "[470]\ttraining's binary_logloss: 0.399261\tvalid_0's binary_logloss: 0.404607\n",
      "[471]\ttraining's binary_logloss: 0.39925\tvalid_0's binary_logloss: 0.40462\n",
      "[472]\ttraining's binary_logloss: 0.399235\tvalid_0's binary_logloss: 0.404621\n",
      "[473]\ttraining's binary_logloss: 0.399216\tvalid_0's binary_logloss: 0.404627\n",
      "[474]\ttraining's binary_logloss: 0.399195\tvalid_0's binary_logloss: 0.404632\n",
      "[475]\ttraining's binary_logloss: 0.39918\tvalid_0's binary_logloss: 0.404627\n",
      "[476]\ttraining's binary_logloss: 0.399165\tvalid_0's binary_logloss: 0.40462\n",
      "[477]\ttraining's binary_logloss: 0.399146\tvalid_0's binary_logloss: 0.404622\n",
      "[478]\ttraining's binary_logloss: 0.39913\tvalid_0's binary_logloss: 0.404599\n",
      "[479]\ttraining's binary_logloss: 0.399111\tvalid_0's binary_logloss: 0.404591\n",
      "[480]\ttraining's binary_logloss: 0.399094\tvalid_0's binary_logloss: 0.4046\n",
      "[481]\ttraining's binary_logloss: 0.399072\tvalid_0's binary_logloss: 0.404596\n",
      "[482]\ttraining's binary_logloss: 0.399057\tvalid_0's binary_logloss: 0.404604\n",
      "[483]\ttraining's binary_logloss: 0.399043\tvalid_0's binary_logloss: 0.404606\n",
      "[484]\ttraining's binary_logloss: 0.399029\tvalid_0's binary_logloss: 0.404596\n",
      "[485]\ttraining's binary_logloss: 0.399012\tvalid_0's binary_logloss: 0.404592\n",
      "[486]\ttraining's binary_logloss: 0.398999\tvalid_0's binary_logloss: 0.404592\n",
      "[487]\ttraining's binary_logloss: 0.398983\tvalid_0's binary_logloss: 0.404597\n",
      "[488]\ttraining's binary_logloss: 0.398964\tvalid_0's binary_logloss: 0.404589\n",
      "[489]\ttraining's binary_logloss: 0.398944\tvalid_0's binary_logloss: 0.404577\n",
      "[490]\ttraining's binary_logloss: 0.398904\tvalid_0's binary_logloss: 0.404536\n",
      "[491]\ttraining's binary_logloss: 0.398885\tvalid_0's binary_logloss: 0.404538\n",
      "[492]\ttraining's binary_logloss: 0.398861\tvalid_0's binary_logloss: 0.404521\n",
      "[493]\ttraining's binary_logloss: 0.398842\tvalid_0's binary_logloss: 0.404514\n",
      "[494]\ttraining's binary_logloss: 0.39883\tvalid_0's binary_logloss: 0.404511\n",
      "[495]\ttraining's binary_logloss: 0.398817\tvalid_0's binary_logloss: 0.404522\n",
      "[496]\ttraining's binary_logloss: 0.3988\tvalid_0's binary_logloss: 0.404524\n",
      "[497]\ttraining's binary_logloss: 0.398782\tvalid_0's binary_logloss: 0.404528\n",
      "[498]\ttraining's binary_logloss: 0.398752\tvalid_0's binary_logloss: 0.404499\n",
      "[499]\ttraining's binary_logloss: 0.398737\tvalid_0's binary_logloss: 0.404497\n",
      "[500]\ttraining's binary_logloss: 0.398724\tvalid_0's binary_logloss: 0.404493\n",
      "[501]\ttraining's binary_logloss: 0.398711\tvalid_0's binary_logloss: 0.404491\n",
      "[502]\ttraining's binary_logloss: 0.398696\tvalid_0's binary_logloss: 0.404502\n",
      "[503]\ttraining's binary_logloss: 0.398679\tvalid_0's binary_logloss: 0.404498\n",
      "[504]\ttraining's binary_logloss: 0.398665\tvalid_0's binary_logloss: 0.404494\n",
      "[505]\ttraining's binary_logloss: 0.398649\tvalid_0's binary_logloss: 0.404509\n",
      "[506]\ttraining's binary_logloss: 0.398627\tvalid_0's binary_logloss: 0.404504\n",
      "[507]\ttraining's binary_logloss: 0.398609\tvalid_0's binary_logloss: 0.404499\n",
      "[508]\ttraining's binary_logloss: 0.39859\tvalid_0's binary_logloss: 0.404487\n",
      "[509]\ttraining's binary_logloss: 0.398574\tvalid_0's binary_logloss: 0.4045\n",
      "[510]\ttraining's binary_logloss: 0.398559\tvalid_0's binary_logloss: 0.40449\n",
      "[511]\ttraining's binary_logloss: 0.398537\tvalid_0's binary_logloss: 0.404483\n",
      "[512]\ttraining's binary_logloss: 0.398517\tvalid_0's binary_logloss: 0.40449\n",
      "[513]\ttraining's binary_logloss: 0.398494\tvalid_0's binary_logloss: 0.40449\n",
      "[514]\ttraining's binary_logloss: 0.398469\tvalid_0's binary_logloss: 0.404472\n",
      "[515]\ttraining's binary_logloss: 0.398457\tvalid_0's binary_logloss: 0.40448\n",
      "[516]\ttraining's binary_logloss: 0.39844\tvalid_0's binary_logloss: 0.404495\n",
      "[517]\ttraining's binary_logloss: 0.398422\tvalid_0's binary_logloss: 0.404477\n",
      "[518]\ttraining's binary_logloss: 0.398407\tvalid_0's binary_logloss: 0.404467\n",
      "[519]\ttraining's binary_logloss: 0.398388\tvalid_0's binary_logloss: 0.404459\n",
      "[520]\ttraining's binary_logloss: 0.398374\tvalid_0's binary_logloss: 0.404447\n",
      "[521]\ttraining's binary_logloss: 0.398363\tvalid_0's binary_logloss: 0.404445\n",
      "[522]\ttraining's binary_logloss: 0.398341\tvalid_0's binary_logloss: 0.404444\n",
      "[523]\ttraining's binary_logloss: 0.398327\tvalid_0's binary_logloss: 0.404433\n",
      "[524]\ttraining's binary_logloss: 0.398312\tvalid_0's binary_logloss: 0.404423\n",
      "[525]\ttraining's binary_logloss: 0.398298\tvalid_0's binary_logloss: 0.404429\n",
      "[526]\ttraining's binary_logloss: 0.398281\tvalid_0's binary_logloss: 0.404429\n",
      "[527]\ttraining's binary_logloss: 0.398218\tvalid_0's binary_logloss: 0.404405\n",
      "[528]\ttraining's binary_logloss: 0.398198\tvalid_0's binary_logloss: 0.404392\n",
      "[529]\ttraining's binary_logloss: 0.398185\tvalid_0's binary_logloss: 0.404397\n",
      "[530]\ttraining's binary_logloss: 0.398172\tvalid_0's binary_logloss: 0.404397\n",
      "[531]\ttraining's binary_logloss: 0.398156\tvalid_0's binary_logloss: 0.404403\n",
      "[532]\ttraining's binary_logloss: 0.39814\tvalid_0's binary_logloss: 0.404391\n",
      "[533]\ttraining's binary_logloss: 0.398122\tvalid_0's binary_logloss: 0.404405\n",
      "[534]\ttraining's binary_logloss: 0.398104\tvalid_0's binary_logloss: 0.404422\n",
      "[535]\ttraining's binary_logloss: 0.398087\tvalid_0's binary_logloss: 0.40441\n",
      "[536]\ttraining's binary_logloss: 0.398069\tvalid_0's binary_logloss: 0.4044\n",
      "[537]\ttraining's binary_logloss: 0.398033\tvalid_0's binary_logloss: 0.404358\n",
      "[538]\ttraining's binary_logloss: 0.398015\tvalid_0's binary_logloss: 0.404348\n",
      "[539]\ttraining's binary_logloss: 0.398001\tvalid_0's binary_logloss: 0.404343\n",
      "[540]\ttraining's binary_logloss: 0.39796\tvalid_0's binary_logloss: 0.404319\n",
      "[541]\ttraining's binary_logloss: 0.397947\tvalid_0's binary_logloss: 0.404314\n",
      "[542]\ttraining's binary_logloss: 0.397932\tvalid_0's binary_logloss: 0.40431\n",
      "[543]\ttraining's binary_logloss: 0.39792\tvalid_0's binary_logloss: 0.404305\n",
      "[544]\ttraining's binary_logloss: 0.397905\tvalid_0's binary_logloss: 0.404307\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[545]\ttraining's binary_logloss: 0.397887\tvalid_0's binary_logloss: 0.404306\n",
      "[546]\ttraining's binary_logloss: 0.397871\tvalid_0's binary_logloss: 0.404311\n",
      "[547]\ttraining's binary_logloss: 0.397859\tvalid_0's binary_logloss: 0.404311\n",
      "[548]\ttraining's binary_logloss: 0.397835\tvalid_0's binary_logloss: 0.40429\n",
      "[549]\ttraining's binary_logloss: 0.397798\tvalid_0's binary_logloss: 0.40427\n",
      "[550]\ttraining's binary_logloss: 0.39778\tvalid_0's binary_logloss: 0.404272\n",
      "[551]\ttraining's binary_logloss: 0.397767\tvalid_0's binary_logloss: 0.404276\n",
      "[552]\ttraining's binary_logloss: 0.39775\tvalid_0's binary_logloss: 0.404275\n",
      "[553]\ttraining's binary_logloss: 0.397737\tvalid_0's binary_logloss: 0.404276\n",
      "[554]\ttraining's binary_logloss: 0.397725\tvalid_0's binary_logloss: 0.404282\n",
      "[555]\ttraining's binary_logloss: 0.39771\tvalid_0's binary_logloss: 0.404281\n",
      "[556]\ttraining's binary_logloss: 0.397691\tvalid_0's binary_logloss: 0.404275\n",
      "[557]\ttraining's binary_logloss: 0.39767\tvalid_0's binary_logloss: 0.40426\n",
      "[558]\ttraining's binary_logloss: 0.397654\tvalid_0's binary_logloss: 0.404268\n",
      "[559]\ttraining's binary_logloss: 0.39764\tvalid_0's binary_logloss: 0.404273\n",
      "[560]\ttraining's binary_logloss: 0.397589\tvalid_0's binary_logloss: 0.404236\n",
      "[561]\ttraining's binary_logloss: 0.397579\tvalid_0's binary_logloss: 0.404229\n",
      "[562]\ttraining's binary_logloss: 0.397563\tvalid_0's binary_logloss: 0.404227\n",
      "[563]\ttraining's binary_logloss: 0.397543\tvalid_0's binary_logloss: 0.404222\n",
      "[564]\ttraining's binary_logloss: 0.397527\tvalid_0's binary_logloss: 0.404228\n",
      "[565]\ttraining's binary_logloss: 0.397511\tvalid_0's binary_logloss: 0.404228\n",
      "[566]\ttraining's binary_logloss: 0.397497\tvalid_0's binary_logloss: 0.404227\n",
      "[567]\ttraining's binary_logloss: 0.39748\tvalid_0's binary_logloss: 0.404225\n",
      "[568]\ttraining's binary_logloss: 0.397465\tvalid_0's binary_logloss: 0.404233\n",
      "[569]\ttraining's binary_logloss: 0.397443\tvalid_0's binary_logloss: 0.40423\n",
      "[570]\ttraining's binary_logloss: 0.397426\tvalid_0's binary_logloss: 0.404234\n",
      "[571]\ttraining's binary_logloss: 0.397396\tvalid_0's binary_logloss: 0.404229\n",
      "[572]\ttraining's binary_logloss: 0.397379\tvalid_0's binary_logloss: 0.404229\n",
      "[573]\ttraining's binary_logloss: 0.397357\tvalid_0's binary_logloss: 0.404217\n",
      "[574]\ttraining's binary_logloss: 0.39734\tvalid_0's binary_logloss: 0.404225\n",
      "[575]\ttraining's binary_logloss: 0.397313\tvalid_0's binary_logloss: 0.404208\n",
      "[576]\ttraining's binary_logloss: 0.397299\tvalid_0's binary_logloss: 0.404198\n",
      "[577]\ttraining's binary_logloss: 0.397268\tvalid_0's binary_logloss: 0.40419\n",
      "[578]\ttraining's binary_logloss: 0.397255\tvalid_0's binary_logloss: 0.404198\n",
      "[579]\ttraining's binary_logloss: 0.397231\tvalid_0's binary_logloss: 0.404199\n",
      "[580]\ttraining's binary_logloss: 0.397216\tvalid_0's binary_logloss: 0.404193\n",
      "[581]\ttraining's binary_logloss: 0.397203\tvalid_0's binary_logloss: 0.404178\n",
      "[582]\ttraining's binary_logloss: 0.397185\tvalid_0's binary_logloss: 0.404185\n",
      "[583]\ttraining's binary_logloss: 0.397169\tvalid_0's binary_logloss: 0.404187\n",
      "[584]\ttraining's binary_logloss: 0.397152\tvalid_0's binary_logloss: 0.404186\n",
      "[585]\ttraining's binary_logloss: 0.397131\tvalid_0's binary_logloss: 0.404189\n",
      "[586]\ttraining's binary_logloss: 0.397093\tvalid_0's binary_logloss: 0.404183\n",
      "[587]\ttraining's binary_logloss: 0.397075\tvalid_0's binary_logloss: 0.404187\n",
      "[588]\ttraining's binary_logloss: 0.397064\tvalid_0's binary_logloss: 0.404203\n",
      "[589]\ttraining's binary_logloss: 0.397037\tvalid_0's binary_logloss: 0.404177\n",
      "[590]\ttraining's binary_logloss: 0.397019\tvalid_0's binary_logloss: 0.404184\n",
      "[591]\ttraining's binary_logloss: 0.397004\tvalid_0's binary_logloss: 0.404189\n",
      "[592]\ttraining's binary_logloss: 0.396995\tvalid_0's binary_logloss: 0.404184\n",
      "[593]\ttraining's binary_logloss: 0.396981\tvalid_0's binary_logloss: 0.404172\n",
      "[594]\ttraining's binary_logloss: 0.396964\tvalid_0's binary_logloss: 0.404162\n",
      "[595]\ttraining's binary_logloss: 0.39695\tvalid_0's binary_logloss: 0.404157\n",
      "[596]\ttraining's binary_logloss: 0.396929\tvalid_0's binary_logloss: 0.404139\n",
      "[597]\ttraining's binary_logloss: 0.396918\tvalid_0's binary_logloss: 0.404128\n",
      "[598]\ttraining's binary_logloss: 0.396906\tvalid_0's binary_logloss: 0.404122\n",
      "[599]\ttraining's binary_logloss: 0.396893\tvalid_0's binary_logloss: 0.404129\n",
      "[600]\ttraining's binary_logloss: 0.396874\tvalid_0's binary_logloss: 0.404138\n",
      "[601]\ttraining's binary_logloss: 0.396856\tvalid_0's binary_logloss: 0.404129\n",
      "[602]\ttraining's binary_logloss: 0.396837\tvalid_0's binary_logloss: 0.404127\n",
      "[603]\ttraining's binary_logloss: 0.396822\tvalid_0's binary_logloss: 0.404124\n",
      "[604]\ttraining's binary_logloss: 0.396803\tvalid_0's binary_logloss: 0.404122\n",
      "[605]\ttraining's binary_logloss: 0.396789\tvalid_0's binary_logloss: 0.404107\n",
      "[606]\ttraining's binary_logloss: 0.396776\tvalid_0's binary_logloss: 0.404109\n",
      "[607]\ttraining's binary_logloss: 0.396761\tvalid_0's binary_logloss: 0.404108\n",
      "[608]\ttraining's binary_logloss: 0.396743\tvalid_0's binary_logloss: 0.4041\n",
      "[609]\ttraining's binary_logloss: 0.396728\tvalid_0's binary_logloss: 0.404101\n",
      "[610]\ttraining's binary_logloss: 0.396716\tvalid_0's binary_logloss: 0.404105\n",
      "[611]\ttraining's binary_logloss: 0.396699\tvalid_0's binary_logloss: 0.404085\n",
      "[612]\ttraining's binary_logloss: 0.396686\tvalid_0's binary_logloss: 0.404077\n",
      "[613]\ttraining's binary_logloss: 0.396667\tvalid_0's binary_logloss: 0.404061\n",
      "[614]\ttraining's binary_logloss: 0.396652\tvalid_0's binary_logloss: 0.404064\n",
      "[615]\ttraining's binary_logloss: 0.396635\tvalid_0's binary_logloss: 0.404064\n",
      "[616]\ttraining's binary_logloss: 0.396621\tvalid_0's binary_logloss: 0.404069\n",
      "[617]\ttraining's binary_logloss: 0.396599\tvalid_0's binary_logloss: 0.404087\n",
      "[618]\ttraining's binary_logloss: 0.396592\tvalid_0's binary_logloss: 0.404084\n",
      "[619]\ttraining's binary_logloss: 0.396572\tvalid_0's binary_logloss: 0.404087\n",
      "[620]\ttraining's binary_logloss: 0.39656\tvalid_0's binary_logloss: 0.404091\n",
      "[621]\ttraining's binary_logloss: 0.396546\tvalid_0's binary_logloss: 0.404078\n",
      "[622]\ttraining's binary_logloss: 0.396534\tvalid_0's binary_logloss: 0.40407\n",
      "[623]\ttraining's binary_logloss: 0.396517\tvalid_0's binary_logloss: 0.404065\n",
      "[624]\ttraining's binary_logloss: 0.396504\tvalid_0's binary_logloss: 0.404072\n",
      "[625]\ttraining's binary_logloss: 0.396487\tvalid_0's binary_logloss: 0.404063\n",
      "[626]\ttraining's binary_logloss: 0.39647\tvalid_0's binary_logloss: 0.404061\n",
      "[627]\ttraining's binary_logloss: 0.396454\tvalid_0's binary_logloss: 0.404062\n",
      "[628]\ttraining's binary_logloss: 0.39643\tvalid_0's binary_logloss: 0.404052\n",
      "[629]\ttraining's binary_logloss: 0.396417\tvalid_0's binary_logloss: 0.404053\n",
      "[630]\ttraining's binary_logloss: 0.396395\tvalid_0's binary_logloss: 0.404074\n",
      "[631]\ttraining's binary_logloss: 0.396374\tvalid_0's binary_logloss: 0.40407\n",
      "[632]\ttraining's binary_logloss: 0.396362\tvalid_0's binary_logloss: 0.404048\n",
      "[633]\ttraining's binary_logloss: 0.39635\tvalid_0's binary_logloss: 0.404063\n",
      "[634]\ttraining's binary_logloss: 0.396335\tvalid_0's binary_logloss: 0.40406\n",
      "[635]\ttraining's binary_logloss: 0.396324\tvalid_0's binary_logloss: 0.40407\n",
      "[636]\ttraining's binary_logloss: 0.396299\tvalid_0's binary_logloss: 0.404082\n",
      "[637]\ttraining's binary_logloss: 0.39628\tvalid_0's binary_logloss: 0.404085\n",
      "[638]\ttraining's binary_logloss: 0.396258\tvalid_0's binary_logloss: 0.404071\n",
      "[639]\ttraining's binary_logloss: 0.396246\tvalid_0's binary_logloss: 0.404061\n",
      "[640]\ttraining's binary_logloss: 0.396232\tvalid_0's binary_logloss: 0.404062\n",
      "[641]\ttraining's binary_logloss: 0.396202\tvalid_0's binary_logloss: 0.404033\n",
      "[642]\ttraining's binary_logloss: 0.396188\tvalid_0's binary_logloss: 0.404033\n",
      "[643]\ttraining's binary_logloss: 0.39617\tvalid_0's binary_logloss: 0.404015\n",
      "[644]\ttraining's binary_logloss: 0.396157\tvalid_0's binary_logloss: 0.404012\n",
      "[645]\ttraining's binary_logloss: 0.396145\tvalid_0's binary_logloss: 0.404014\n",
      "[646]\ttraining's binary_logloss: 0.396111\tvalid_0's binary_logloss: 0.403975\n",
      "[647]\ttraining's binary_logloss: 0.396093\tvalid_0's binary_logloss: 0.403983\n",
      "[648]\ttraining's binary_logloss: 0.396076\tvalid_0's binary_logloss: 0.40397\n",
      "[649]\ttraining's binary_logloss: 0.396047\tvalid_0's binary_logloss: 0.403968\n",
      "[650]\ttraining's binary_logloss: 0.396017\tvalid_0's binary_logloss: 0.403945\n",
      "[651]\ttraining's binary_logloss: 0.395998\tvalid_0's binary_logloss: 0.403954\n",
      "[652]\ttraining's binary_logloss: 0.395987\tvalid_0's binary_logloss: 0.40395\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[653]\ttraining's binary_logloss: 0.395973\tvalid_0's binary_logloss: 0.40395\n",
      "[654]\ttraining's binary_logloss: 0.395962\tvalid_0's binary_logloss: 0.403949\n",
      "[655]\ttraining's binary_logloss: 0.395945\tvalid_0's binary_logloss: 0.403939\n",
      "[656]\ttraining's binary_logloss: 0.395932\tvalid_0's binary_logloss: 0.403946\n",
      "[657]\ttraining's binary_logloss: 0.395919\tvalid_0's binary_logloss: 0.403946\n",
      "[658]\ttraining's binary_logloss: 0.395905\tvalid_0's binary_logloss: 0.403942\n",
      "[659]\ttraining's binary_logloss: 0.395893\tvalid_0's binary_logloss: 0.403945\n",
      "[660]\ttraining's binary_logloss: 0.39587\tvalid_0's binary_logloss: 0.403934\n",
      "[661]\ttraining's binary_logloss: 0.395855\tvalid_0's binary_logloss: 0.403946\n",
      "[662]\ttraining's binary_logloss: 0.395837\tvalid_0's binary_logloss: 0.403943\n",
      "[663]\ttraining's binary_logloss: 0.395815\tvalid_0's binary_logloss: 0.40395\n",
      "[664]\ttraining's binary_logloss: 0.395799\tvalid_0's binary_logloss: 0.403957\n",
      "[665]\ttraining's binary_logloss: 0.395783\tvalid_0's binary_logloss: 0.403949\n",
      "[666]\ttraining's binary_logloss: 0.395768\tvalid_0's binary_logloss: 0.403949\n",
      "[667]\ttraining's binary_logloss: 0.395753\tvalid_0's binary_logloss: 0.403945\n",
      "[668]\ttraining's binary_logloss: 0.395734\tvalid_0's binary_logloss: 0.40394\n",
      "[669]\ttraining's binary_logloss: 0.395711\tvalid_0's binary_logloss: 0.40394\n",
      "[670]\ttraining's binary_logloss: 0.395681\tvalid_0's binary_logloss: 0.403919\n",
      "[671]\ttraining's binary_logloss: 0.395664\tvalid_0's binary_logloss: 0.403918\n",
      "[672]\ttraining's binary_logloss: 0.395648\tvalid_0's binary_logloss: 0.40392\n",
      "[673]\ttraining's binary_logloss: 0.395633\tvalid_0's binary_logloss: 0.403906\n",
      "[674]\ttraining's binary_logloss: 0.395621\tvalid_0's binary_logloss: 0.403916\n",
      "[675]\ttraining's binary_logloss: 0.395607\tvalid_0's binary_logloss: 0.403925\n",
      "[676]\ttraining's binary_logloss: 0.395595\tvalid_0's binary_logloss: 0.403929\n",
      "[677]\ttraining's binary_logloss: 0.395582\tvalid_0's binary_logloss: 0.403921\n",
      "[678]\ttraining's binary_logloss: 0.395569\tvalid_0's binary_logloss: 0.403927\n",
      "[679]\ttraining's binary_logloss: 0.395548\tvalid_0's binary_logloss: 0.403929\n",
      "[680]\ttraining's binary_logloss: 0.395531\tvalid_0's binary_logloss: 0.403927\n",
      "[681]\ttraining's binary_logloss: 0.395505\tvalid_0's binary_logloss: 0.403915\n",
      "[682]\ttraining's binary_logloss: 0.395484\tvalid_0's binary_logloss: 0.403899\n",
      "[683]\ttraining's binary_logloss: 0.395465\tvalid_0's binary_logloss: 0.403905\n",
      "[684]\ttraining's binary_logloss: 0.395448\tvalid_0's binary_logloss: 0.403909\n",
      "[685]\ttraining's binary_logloss: 0.395431\tvalid_0's binary_logloss: 0.40391\n",
      "[686]\ttraining's binary_logloss: 0.395417\tvalid_0's binary_logloss: 0.403924\n",
      "[687]\ttraining's binary_logloss: 0.395405\tvalid_0's binary_logloss: 0.403938\n",
      "[688]\ttraining's binary_logloss: 0.395389\tvalid_0's binary_logloss: 0.403952\n",
      "[689]\ttraining's binary_logloss: 0.39537\tvalid_0's binary_logloss: 0.40395\n",
      "[690]\ttraining's binary_logloss: 0.395353\tvalid_0's binary_logloss: 0.403942\n",
      "[691]\ttraining's binary_logloss: 0.395339\tvalid_0's binary_logloss: 0.40394\n",
      "[692]\ttraining's binary_logloss: 0.395328\tvalid_0's binary_logloss: 0.403945\n",
      "[693]\ttraining's binary_logloss: 0.395315\tvalid_0's binary_logloss: 0.403942\n",
      "[694]\ttraining's binary_logloss: 0.395298\tvalid_0's binary_logloss: 0.403955\n",
      "[695]\ttraining's binary_logloss: 0.395288\tvalid_0's binary_logloss: 0.403954\n",
      "[696]\ttraining's binary_logloss: 0.395269\tvalid_0's binary_logloss: 0.403956\n",
      "[697]\ttraining's binary_logloss: 0.395253\tvalid_0's binary_logloss: 0.403954\n",
      "[698]\ttraining's binary_logloss: 0.395235\tvalid_0's binary_logloss: 0.403955\n",
      "[699]\ttraining's binary_logloss: 0.395222\tvalid_0's binary_logloss: 0.403964\n",
      "[700]\ttraining's binary_logloss: 0.395211\tvalid_0's binary_logloss: 0.403952\n",
      "[701]\ttraining's binary_logloss: 0.395193\tvalid_0's binary_logloss: 0.403937\n",
      "[702]\ttraining's binary_logloss: 0.39518\tvalid_0's binary_logloss: 0.403938\n",
      "[703]\ttraining's binary_logloss: 0.39514\tvalid_0's binary_logloss: 0.403904\n",
      "[704]\ttraining's binary_logloss: 0.395123\tvalid_0's binary_logloss: 0.403896\n",
      "[705]\ttraining's binary_logloss: 0.395108\tvalid_0's binary_logloss: 0.403899\n",
      "[706]\ttraining's binary_logloss: 0.395084\tvalid_0's binary_logloss: 0.403874\n",
      "[707]\ttraining's binary_logloss: 0.395069\tvalid_0's binary_logloss: 0.403888\n",
      "[708]\ttraining's binary_logloss: 0.395052\tvalid_0's binary_logloss: 0.403886\n",
      "[709]\ttraining's binary_logloss: 0.395033\tvalid_0's binary_logloss: 0.403891\n",
      "[710]\ttraining's binary_logloss: 0.39502\tvalid_0's binary_logloss: 0.403902\n",
      "[711]\ttraining's binary_logloss: 0.395002\tvalid_0's binary_logloss: 0.403897\n",
      "[712]\ttraining's binary_logloss: 0.394992\tvalid_0's binary_logloss: 0.403896\n",
      "[713]\ttraining's binary_logloss: 0.394978\tvalid_0's binary_logloss: 0.403902\n",
      "[714]\ttraining's binary_logloss: 0.394959\tvalid_0's binary_logloss: 0.403897\n",
      "[715]\ttraining's binary_logloss: 0.394939\tvalid_0's binary_logloss: 0.403902\n",
      "[716]\ttraining's binary_logloss: 0.394908\tvalid_0's binary_logloss: 0.40389\n",
      "[717]\ttraining's binary_logloss: 0.394895\tvalid_0's binary_logloss: 0.403887\n",
      "[718]\ttraining's binary_logloss: 0.394882\tvalid_0's binary_logloss: 0.403897\n",
      "[719]\ttraining's binary_logloss: 0.394867\tvalid_0's binary_logloss: 0.403887\n",
      "[720]\ttraining's binary_logloss: 0.394848\tvalid_0's binary_logloss: 0.403903\n",
      "[721]\ttraining's binary_logloss: 0.394833\tvalid_0's binary_logloss: 0.403894\n",
      "[722]\ttraining's binary_logloss: 0.394816\tvalid_0's binary_logloss: 0.403886\n",
      "[723]\ttraining's binary_logloss: 0.394803\tvalid_0's binary_logloss: 0.403885\n",
      "[724]\ttraining's binary_logloss: 0.394787\tvalid_0's binary_logloss: 0.403874\n",
      "[725]\ttraining's binary_logloss: 0.394778\tvalid_0's binary_logloss: 0.403875\n",
      "[726]\ttraining's binary_logloss: 0.394768\tvalid_0's binary_logloss: 0.403872\n",
      "[727]\ttraining's binary_logloss: 0.394753\tvalid_0's binary_logloss: 0.403889\n",
      "[728]\ttraining's binary_logloss: 0.39474\tvalid_0's binary_logloss: 0.403902\n",
      "[729]\ttraining's binary_logloss: 0.394725\tvalid_0's binary_logloss: 0.4039\n",
      "[730]\ttraining's binary_logloss: 0.394709\tvalid_0's binary_logloss: 0.40391\n",
      "[731]\ttraining's binary_logloss: 0.394694\tvalid_0's binary_logloss: 0.4039\n",
      "[732]\ttraining's binary_logloss: 0.394679\tvalid_0's binary_logloss: 0.403897\n",
      "[733]\ttraining's binary_logloss: 0.394663\tvalid_0's binary_logloss: 0.403901\n",
      "[734]\ttraining's binary_logloss: 0.394652\tvalid_0's binary_logloss: 0.403894\n",
      "[735]\ttraining's binary_logloss: 0.394635\tvalid_0's binary_logloss: 0.403891\n",
      "[736]\ttraining's binary_logloss: 0.394618\tvalid_0's binary_logloss: 0.403888\n",
      "[737]\ttraining's binary_logloss: 0.394603\tvalid_0's binary_logloss: 0.403894\n",
      "[738]\ttraining's binary_logloss: 0.394589\tvalid_0's binary_logloss: 0.403889\n",
      "[739]\ttraining's binary_logloss: 0.394573\tvalid_0's binary_logloss: 0.403892\n",
      "[740]\ttraining's binary_logloss: 0.394563\tvalid_0's binary_logloss: 0.403902\n",
      "[741]\ttraining's binary_logloss: 0.39455\tvalid_0's binary_logloss: 0.403898\n",
      "[742]\ttraining's binary_logloss: 0.394538\tvalid_0's binary_logloss: 0.403894\n",
      "[743]\ttraining's binary_logloss: 0.394527\tvalid_0's binary_logloss: 0.403895\n",
      "[744]\ttraining's binary_logloss: 0.394515\tvalid_0's binary_logloss: 0.403901\n",
      "[745]\ttraining's binary_logloss: 0.394502\tvalid_0's binary_logloss: 0.40391\n",
      "[746]\ttraining's binary_logloss: 0.39449\tvalid_0's binary_logloss: 0.403909\n",
      "[747]\ttraining's binary_logloss: 0.394477\tvalid_0's binary_logloss: 0.403921\n",
      "[748]\ttraining's binary_logloss: 0.394461\tvalid_0's binary_logloss: 0.403923\n",
      "[749]\ttraining's binary_logloss: 0.394447\tvalid_0's binary_logloss: 0.403924\n",
      "[750]\ttraining's binary_logloss: 0.394433\tvalid_0's binary_logloss: 0.403935\n",
      "[751]\ttraining's binary_logloss: 0.39442\tvalid_0's binary_logloss: 0.403934\n",
      "[752]\ttraining's binary_logloss: 0.39441\tvalid_0's binary_logloss: 0.403941\n",
      "[753]\ttraining's binary_logloss: 0.394394\tvalid_0's binary_logloss: 0.403952\n",
      "[754]\ttraining's binary_logloss: 0.394373\tvalid_0's binary_logloss: 0.403927\n",
      "[755]\ttraining's binary_logloss: 0.394358\tvalid_0's binary_logloss: 0.403934\n",
      "[756]\ttraining's binary_logloss: 0.394347\tvalid_0's binary_logloss: 0.403944\n",
      "[757]\ttraining's binary_logloss: 0.394337\tvalid_0's binary_logloss: 0.40394\n",
      "[758]\ttraining's binary_logloss: 0.394323\tvalid_0's binary_logloss: 0.403935\n",
      "[759]\ttraining's binary_logloss: 0.394307\tvalid_0's binary_logloss: 0.403926\n",
      "[760]\ttraining's binary_logloss: 0.394289\tvalid_0's binary_logloss: 0.403935\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[761]\ttraining's binary_logloss: 0.394272\tvalid_0's binary_logloss: 0.403949\n",
      "[762]\ttraining's binary_logloss: 0.394257\tvalid_0's binary_logloss: 0.403944\n",
      "[763]\ttraining's binary_logloss: 0.394246\tvalid_0's binary_logloss: 0.403939\n",
      "[764]\ttraining's binary_logloss: 0.394229\tvalid_0's binary_logloss: 0.403929\n",
      "[765]\ttraining's binary_logloss: 0.394215\tvalid_0's binary_logloss: 0.403921\n",
      "[766]\ttraining's binary_logloss: 0.3942\tvalid_0's binary_logloss: 0.403917\n",
      "[767]\ttraining's binary_logloss: 0.394188\tvalid_0's binary_logloss: 0.403917\n",
      "[768]\ttraining's binary_logloss: 0.394177\tvalid_0's binary_logloss: 0.403922\n",
      "[769]\ttraining's binary_logloss: 0.394157\tvalid_0's binary_logloss: 0.403939\n",
      "[770]\ttraining's binary_logloss: 0.39414\tvalid_0's binary_logloss: 0.403945\n",
      "[771]\ttraining's binary_logloss: 0.394126\tvalid_0's binary_logloss: 0.403947\n",
      "[772]\ttraining's binary_logloss: 0.394094\tvalid_0's binary_logloss: 0.403938\n",
      "[773]\ttraining's binary_logloss: 0.394076\tvalid_0's binary_logloss: 0.403939\n",
      "[774]\ttraining's binary_logloss: 0.394064\tvalid_0's binary_logloss: 0.403937\n",
      "[775]\ttraining's binary_logloss: 0.394046\tvalid_0's binary_logloss: 0.403925\n",
      "[776]\ttraining's binary_logloss: 0.394031\tvalid_0's binary_logloss: 0.403922\n",
      "Early stopping, best iteration is:\n",
      "[726]\ttraining's binary_logloss: 0.394768\tvalid_0's binary_logloss: 0.403872\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "params={}\n",
    "params['learning_rate']= 0.1700\n",
    "params['boosting_type']='gbdt'\n",
    "params['objective']='binary'\n",
    "params['metric']='binary_logloss'\n",
    "params['sub_feature']=0.5\n",
    "params['num_leaves']= 10\n",
    "params['min_data']=30\n",
    "params['max_depth']=10\n",
    "d_train = lgb.Dataset(x_train, label=y_train )\n",
    "d_test =  lgb.Dataset( x_test, label= y_test)\n",
    "evals_result={}\n",
    "lgb.train()\n",
    "model=lgb.train(params,d_train,1000,\n",
    "                valid_sets=[d_test,d_train],verbose_eval=True,\n",
    "                early_stopping_rounds=50,evals_result=evals_result)\n",
    "ax = lgb.plot_metric(evals_result, metric='binary_logloss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#if learning rate is fixed and rounds is increased to 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's binary_logloss: 0.474271\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[2]\tvalid_0's binary_logloss: 0.468593\n",
      "[3]\tvalid_0's binary_logloss: 0.464431\n",
      "[4]\tvalid_0's binary_logloss: 0.46017\n",
      "[5]\tvalid_0's binary_logloss: 0.457219\n",
      "[6]\tvalid_0's binary_logloss: 0.454532\n",
      "[7]\tvalid_0's binary_logloss: 0.451648\n",
      "[8]\tvalid_0's binary_logloss: 0.449658\n",
      "[9]\tvalid_0's binary_logloss: 0.448201\n",
      "[10]\tvalid_0's binary_logloss: 0.446828\n",
      "[11]\tvalid_0's binary_logloss: 0.4454\n",
      "[12]\tvalid_0's binary_logloss: 0.44369\n",
      "[13]\tvalid_0's binary_logloss: 0.441681\n",
      "[14]\tvalid_0's binary_logloss: 0.44078\n",
      "[15]\tvalid_0's binary_logloss: 0.439526\n",
      "[16]\tvalid_0's binary_logloss: 0.438649\n",
      "[17]\tvalid_0's binary_logloss: 0.437241\n",
      "[18]\tvalid_0's binary_logloss: 0.436377\n",
      "[19]\tvalid_0's binary_logloss: 0.43521\n",
      "[20]\tvalid_0's binary_logloss: 0.43448\n",
      "[21]\tvalid_0's binary_logloss: 0.433578\n",
      "[22]\tvalid_0's binary_logloss: 0.432621\n",
      "[23]\tvalid_0's binary_logloss: 0.431834\n",
      "[24]\tvalid_0's binary_logloss: 0.431302\n",
      "[25]\tvalid_0's binary_logloss: 0.430759\n",
      "[26]\tvalid_0's binary_logloss: 0.429863\n",
      "[27]\tvalid_0's binary_logloss: 0.429353\n",
      "[28]\tvalid_0's binary_logloss: 0.428803\n",
      "[29]\tvalid_0's binary_logloss: 0.428238\n",
      "[30]\tvalid_0's binary_logloss: 0.427783\n",
      "[31]\tvalid_0's binary_logloss: 0.427254\n",
      "[32]\tvalid_0's binary_logloss: 0.426612\n",
      "[33]\tvalid_0's binary_logloss: 0.426174\n",
      "[34]\tvalid_0's binary_logloss: 0.425827\n",
      "[35]\tvalid_0's binary_logloss: 0.425511\n",
      "[36]\tvalid_0's binary_logloss: 0.425016\n",
      "[37]\tvalid_0's binary_logloss: 0.424582\n",
      "[38]\tvalid_0's binary_logloss: 0.424324\n",
      "[39]\tvalid_0's binary_logloss: 0.423895\n",
      "[40]\tvalid_0's binary_logloss: 0.423625\n",
      "[41]\tvalid_0's binary_logloss: 0.423199\n",
      "[42]\tvalid_0's binary_logloss: 0.422875\n",
      "[43]\tvalid_0's binary_logloss: 0.422605\n",
      "[44]\tvalid_0's binary_logloss: 0.422419\n",
      "[45]\tvalid_0's binary_logloss: 0.422171\n",
      "[46]\tvalid_0's binary_logloss: 0.421942\n",
      "[47]\tvalid_0's binary_logloss: 0.421676\n",
      "[48]\tvalid_0's binary_logloss: 0.421428\n",
      "[49]\tvalid_0's binary_logloss: 0.421118\n",
      "[50]\tvalid_0's binary_logloss: 0.420859\n",
      "[51]\tvalid_0's binary_logloss: 0.420592\n",
      "[52]\tvalid_0's binary_logloss: 0.420257\n",
      "[53]\tvalid_0's binary_logloss: 0.420112\n",
      "[54]\tvalid_0's binary_logloss: 0.419816\n",
      "[55]\tvalid_0's binary_logloss: 0.419609\n",
      "[56]\tvalid_0's binary_logloss: 0.419486\n",
      "[57]\tvalid_0's binary_logloss: 0.419286\n",
      "[58]\tvalid_0's binary_logloss: 0.419147\n",
      "[59]\tvalid_0's binary_logloss: 0.418949\n",
      "[60]\tvalid_0's binary_logloss: 0.418727\n",
      "[61]\tvalid_0's binary_logloss: 0.418604\n",
      "[62]\tvalid_0's binary_logloss: 0.418169\n",
      "[63]\tvalid_0's binary_logloss: 0.418066\n",
      "[64]\tvalid_0's binary_logloss: 0.417906\n",
      "[65]\tvalid_0's binary_logloss: 0.417653\n",
      "[66]\tvalid_0's binary_logloss: 0.417547\n",
      "[67]\tvalid_0's binary_logloss: 0.417405\n",
      "[68]\tvalid_0's binary_logloss: 0.417275\n",
      "[69]\tvalid_0's binary_logloss: 0.417172\n",
      "[70]\tvalid_0's binary_logloss: 0.416995\n",
      "[71]\tvalid_0's binary_logloss: 0.416865\n",
      "[72]\tvalid_0's binary_logloss: 0.416581\n",
      "[73]\tvalid_0's binary_logloss: 0.416437\n",
      "[74]\tvalid_0's binary_logloss: 0.416137\n",
      "[75]\tvalid_0's binary_logloss: 0.416047\n",
      "[76]\tvalid_0's binary_logloss: 0.415892\n",
      "[77]\tvalid_0's binary_logloss: 0.41577\n",
      "[78]\tvalid_0's binary_logloss: 0.415673\n",
      "[79]\tvalid_0's binary_logloss: 0.415604\n",
      "[80]\tvalid_0's binary_logloss: 0.415476\n",
      "[81]\tvalid_0's binary_logloss: 0.41531\n",
      "[82]\tvalid_0's binary_logloss: 0.415237\n",
      "[83]\tvalid_0's binary_logloss: 0.414997\n",
      "[84]\tvalid_0's binary_logloss: 0.414767\n",
      "[85]\tvalid_0's binary_logloss: 0.414624\n",
      "[86]\tvalid_0's binary_logloss: 0.414481\n",
      "[87]\tvalid_0's binary_logloss: 0.414371\n",
      "[88]\tvalid_0's binary_logloss: 0.414284\n",
      "[89]\tvalid_0's binary_logloss: 0.414244\n",
      "[90]\tvalid_0's binary_logloss: 0.414076\n",
      "[91]\tvalid_0's binary_logloss: 0.413994\n",
      "[92]\tvalid_0's binary_logloss: 0.413941\n",
      "[93]\tvalid_0's binary_logloss: 0.413859\n",
      "[94]\tvalid_0's binary_logloss: 0.413796\n",
      "[95]\tvalid_0's binary_logloss: 0.41368\n",
      "[96]\tvalid_0's binary_logloss: 0.413639\n",
      "[97]\tvalid_0's binary_logloss: 0.413516\n",
      "[98]\tvalid_0's binary_logloss: 0.413436\n",
      "[99]\tvalid_0's binary_logloss: 0.413383\n",
      "[100]\tvalid_0's binary_logloss: 0.413077\n",
      "[101]\tvalid_0's binary_logloss: 0.413016\n",
      "[102]\tvalid_0's binary_logloss: 0.412947\n",
      "[103]\tvalid_0's binary_logloss: 0.412803\n",
      "[104]\tvalid_0's binary_logloss: 0.412763\n",
      "[105]\tvalid_0's binary_logloss: 0.412681\n",
      "[106]\tvalid_0's binary_logloss: 0.412636\n",
      "[107]\tvalid_0's binary_logloss: 0.4126\n",
      "[108]\tvalid_0's binary_logloss: 0.412502\n",
      "[109]\tvalid_0's binary_logloss: 0.412435\n",
      "[110]\tvalid_0's binary_logloss: 0.412349\n",
      "[111]\tvalid_0's binary_logloss: 0.412308\n",
      "[112]\tvalid_0's binary_logloss: 0.412117\n",
      "[113]\tvalid_0's binary_logloss: 0.412064\n",
      "[114]\tvalid_0's binary_logloss: 0.411987\n",
      "[115]\tvalid_0's binary_logloss: 0.411862\n",
      "[116]\tvalid_0's binary_logloss: 0.411829\n",
      "[117]\tvalid_0's binary_logloss: 0.411767\n",
      "[118]\tvalid_0's binary_logloss: 0.4117\n",
      "[119]\tvalid_0's binary_logloss: 0.411689\n",
      "[120]\tvalid_0's binary_logloss: 0.411621\n",
      "[121]\tvalid_0's binary_logloss: 0.411584\n",
      "[122]\tvalid_0's binary_logloss: 0.411538\n",
      "[123]\tvalid_0's binary_logloss: 0.411486\n",
      "[124]\tvalid_0's binary_logloss: 0.411469\n",
      "[125]\tvalid_0's binary_logloss: 0.41143\n",
      "[126]\tvalid_0's binary_logloss: 0.411234\n",
      "[127]\tvalid_0's binary_logloss: 0.41119\n",
      "[128]\tvalid_0's binary_logloss: 0.411169\n",
      "[129]\tvalid_0's binary_logloss: 0.411127\n",
      "[130]\tvalid_0's binary_logloss: 0.411074\n",
      "[131]\tvalid_0's binary_logloss: 0.411014\n",
      "[132]\tvalid_0's binary_logloss: 0.411001\n",
      "[133]\tvalid_0's binary_logloss: 0.410932\n",
      "[134]\tvalid_0's binary_logloss: 0.410883\n",
      "[135]\tvalid_0's binary_logloss: 0.410835\n",
      "[136]\tvalid_0's binary_logloss: 0.410814\n",
      "[137]\tvalid_0's binary_logloss: 0.410803\n",
      "[138]\tvalid_0's binary_logloss: 0.410638\n",
      "[139]\tvalid_0's binary_logloss: 0.410512\n",
      "[140]\tvalid_0's binary_logloss: 0.410408\n",
      "[141]\tvalid_0's binary_logloss: 0.410394\n",
      "[142]\tvalid_0's binary_logloss: 0.410294\n",
      "[143]\tvalid_0's binary_logloss: 0.410237\n",
      "[144]\tvalid_0's binary_logloss: 0.41023\n",
      "[145]\tvalid_0's binary_logloss: 0.410218\n",
      "[146]\tvalid_0's binary_logloss: 0.410182\n",
      "[147]\tvalid_0's binary_logloss: 0.410156\n",
      "[148]\tvalid_0's binary_logloss: 0.410146\n",
      "[149]\tvalid_0's binary_logloss: 0.410098\n",
      "[150]\tvalid_0's binary_logloss: 0.410062\n",
      "[151]\tvalid_0's binary_logloss: 0.41005\n",
      "[152]\tvalid_0's binary_logloss: 0.410033\n",
      "[153]\tvalid_0's binary_logloss: 0.409853\n",
      "[154]\tvalid_0's binary_logloss: 0.409813\n",
      "[155]\tvalid_0's binary_logloss: 0.409786\n",
      "[156]\tvalid_0's binary_logloss: 0.409765\n",
      "[157]\tvalid_0's binary_logloss: 0.409718\n",
      "[158]\tvalid_0's binary_logloss: 0.409502\n",
      "[159]\tvalid_0's binary_logloss: 0.409471\n",
      "[160]\tvalid_0's binary_logloss: 0.409446\n",
      "[161]\tvalid_0's binary_logloss: 0.409426\n",
      "[162]\tvalid_0's binary_logloss: 0.409329\n",
      "[163]\tvalid_0's binary_logloss: 0.409309\n",
      "[164]\tvalid_0's binary_logloss: 0.409119\n",
      "[165]\tvalid_0's binary_logloss: 0.409102\n",
      "[166]\tvalid_0's binary_logloss: 0.409012\n",
      "[167]\tvalid_0's binary_logloss: 0.409007\n",
      "[168]\tvalid_0's binary_logloss: 0.408989\n",
      "[169]\tvalid_0's binary_logloss: 0.408989\n",
      "[170]\tvalid_0's binary_logloss: 0.408889\n",
      "[171]\tvalid_0's binary_logloss: 0.40888\n",
      "[172]\tvalid_0's binary_logloss: 0.408884\n",
      "[173]\tvalid_0's binary_logloss: 0.408855\n",
      "[174]\tvalid_0's binary_logloss: 0.408669\n",
      "[175]\tvalid_0's binary_logloss: 0.40854\n",
      "[176]\tvalid_0's binary_logloss: 0.408504\n",
      "[177]\tvalid_0's binary_logloss: 0.408506\n",
      "[178]\tvalid_0's binary_logloss: 0.408472\n",
      "[179]\tvalid_0's binary_logloss: 0.408445\n",
      "[180]\tvalid_0's binary_logloss: 0.408363\n",
      "[181]\tvalid_0's binary_logloss: 0.408328\n",
      "[182]\tvalid_0's binary_logloss: 0.408196\n",
      "[183]\tvalid_0's binary_logloss: 0.408193\n",
      "[184]\tvalid_0's binary_logloss: 0.408099\n",
      "[185]\tvalid_0's binary_logloss: 0.408091\n",
      "[186]\tvalid_0's binary_logloss: 0.408087\n",
      "[187]\tvalid_0's binary_logloss: 0.408065\n",
      "[188]\tvalid_0's binary_logloss: 0.407916\n",
      "[189]\tvalid_0's binary_logloss: 0.407826\n",
      "[190]\tvalid_0's binary_logloss: 0.407811\n",
      "[191]\tvalid_0's binary_logloss: 0.407796\n",
      "[192]\tvalid_0's binary_logloss: 0.407782\n",
      "[193]\tvalid_0's binary_logloss: 0.407761\n",
      "[194]\tvalid_0's binary_logloss: 0.407713\n",
      "[195]\tvalid_0's binary_logloss: 0.407705\n",
      "[196]\tvalid_0's binary_logloss: 0.4077\n",
      "[197]\tvalid_0's binary_logloss: 0.407675\n",
      "[198]\tvalid_0's binary_logloss: 0.407672\n",
      "[199]\tvalid_0's binary_logloss: 0.407658\n",
      "[200]\tvalid_0's binary_logloss: 0.407645\n",
      "[201]\tvalid_0's binary_logloss: 0.407623\n",
      "[202]\tvalid_0's binary_logloss: 0.407629\n",
      "[203]\tvalid_0's binary_logloss: 0.407614\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[204]\tvalid_0's binary_logloss: 0.407598\n",
      "[205]\tvalid_0's binary_logloss: 0.407494\n",
      "[206]\tvalid_0's binary_logloss: 0.407422\n",
      "[207]\tvalid_0's binary_logloss: 0.407422\n",
      "[208]\tvalid_0's binary_logloss: 0.407429\n",
      "[209]\tvalid_0's binary_logloss: 0.407427\n",
      "[210]\tvalid_0's binary_logloss: 0.407383\n",
      "[211]\tvalid_0's binary_logloss: 0.407387\n",
      "[212]\tvalid_0's binary_logloss: 0.407358\n",
      "[213]\tvalid_0's binary_logloss: 0.407349\n",
      "[214]\tvalid_0's binary_logloss: 0.407303\n",
      "[215]\tvalid_0's binary_logloss: 0.407299\n",
      "[216]\tvalid_0's binary_logloss: 0.407305\n",
      "[217]\tvalid_0's binary_logloss: 0.40725\n",
      "[218]\tvalid_0's binary_logloss: 0.407103\n",
      "[219]\tvalid_0's binary_logloss: 0.407017\n",
      "[220]\tvalid_0's binary_logloss: 0.407002\n",
      "[221]\tvalid_0's binary_logloss: 0.406986\n",
      "[222]\tvalid_0's binary_logloss: 0.406967\n",
      "[223]\tvalid_0's binary_logloss: 0.406927\n",
      "[224]\tvalid_0's binary_logloss: 0.406802\n",
      "[225]\tvalid_0's binary_logloss: 0.406784\n",
      "[226]\tvalid_0's binary_logloss: 0.406766\n",
      "[227]\tvalid_0's binary_logloss: 0.406703\n",
      "[228]\tvalid_0's binary_logloss: 0.406705\n",
      "[229]\tvalid_0's binary_logloss: 0.4067\n",
      "[230]\tvalid_0's binary_logloss: 0.406695\n",
      "[231]\tvalid_0's binary_logloss: 0.406676\n",
      "[232]\tvalid_0's binary_logloss: 0.406652\n",
      "[233]\tvalid_0's binary_logloss: 0.406656\n",
      "[234]\tvalid_0's binary_logloss: 0.40664\n",
      "[235]\tvalid_0's binary_logloss: 0.40663\n",
      "[236]\tvalid_0's binary_logloss: 0.406626\n",
      "[237]\tvalid_0's binary_logloss: 0.406565\n",
      "[238]\tvalid_0's binary_logloss: 0.406575\n",
      "[239]\tvalid_0's binary_logloss: 0.406574\n",
      "[240]\tvalid_0's binary_logloss: 0.406492\n",
      "[241]\tvalid_0's binary_logloss: 0.406393\n",
      "[242]\tvalid_0's binary_logloss: 0.40638\n",
      "[243]\tvalid_0's binary_logloss: 0.406333\n",
      "[244]\tvalid_0's binary_logloss: 0.406238\n",
      "[245]\tvalid_0's binary_logloss: 0.406238\n",
      "[246]\tvalid_0's binary_logloss: 0.406238\n",
      "[247]\tvalid_0's binary_logloss: 0.406139\n",
      "[248]\tvalid_0's binary_logloss: 0.406129\n",
      "[249]\tvalid_0's binary_logloss: 0.406123\n",
      "[250]\tvalid_0's binary_logloss: 0.406125\n",
      "[251]\tvalid_0's binary_logloss: 0.406112\n",
      "[252]\tvalid_0's binary_logloss: 0.406105\n",
      "[253]\tvalid_0's binary_logloss: 0.406099\n",
      "[254]\tvalid_0's binary_logloss: 0.406018\n",
      "[255]\tvalid_0's binary_logloss: 0.406006\n",
      "[256]\tvalid_0's binary_logloss: 0.405902\n",
      "[257]\tvalid_0's binary_logloss: 0.405893\n",
      "[258]\tvalid_0's binary_logloss: 0.405854\n",
      "[259]\tvalid_0's binary_logloss: 0.405851\n",
      "[260]\tvalid_0's binary_logloss: 0.40583\n",
      "[261]\tvalid_0's binary_logloss: 0.405811\n",
      "[262]\tvalid_0's binary_logloss: 0.405746\n",
      "[263]\tvalid_0's binary_logloss: 0.40575\n",
      "[264]\tvalid_0's binary_logloss: 0.405683\n",
      "[265]\tvalid_0's binary_logloss: 0.405687\n",
      "[266]\tvalid_0's binary_logloss: 0.40568\n",
      "[267]\tvalid_0's binary_logloss: 0.405678\n",
      "[268]\tvalid_0's binary_logloss: 0.405676\n",
      "[269]\tvalid_0's binary_logloss: 0.405675\n",
      "[270]\tvalid_0's binary_logloss: 0.405684\n",
      "[271]\tvalid_0's binary_logloss: 0.405695\n",
      "[272]\tvalid_0's binary_logloss: 0.405694\n",
      "[273]\tvalid_0's binary_logloss: 0.405707\n",
      "[274]\tvalid_0's binary_logloss: 0.40569\n",
      "[275]\tvalid_0's binary_logloss: 0.405682\n",
      "[276]\tvalid_0's binary_logloss: 0.405674\n",
      "[277]\tvalid_0's binary_logloss: 0.40567\n",
      "[278]\tvalid_0's binary_logloss: 0.405673\n",
      "[279]\tvalid_0's binary_logloss: 0.405594\n",
      "[280]\tvalid_0's binary_logloss: 0.405583\n",
      "[281]\tvalid_0's binary_logloss: 0.405577\n",
      "[282]\tvalid_0's binary_logloss: 0.405555\n",
      "[283]\tvalid_0's binary_logloss: 0.405556\n",
      "[284]\tvalid_0's binary_logloss: 0.405559\n",
      "[285]\tvalid_0's binary_logloss: 0.405545\n",
      "[286]\tvalid_0's binary_logloss: 0.405531\n",
      "[287]\tvalid_0's binary_logloss: 0.405519\n",
      "[288]\tvalid_0's binary_logloss: 0.405513\n",
      "[289]\tvalid_0's binary_logloss: 0.405522\n",
      "[290]\tvalid_0's binary_logloss: 0.405505\n",
      "[291]\tvalid_0's binary_logloss: 0.405503\n",
      "[292]\tvalid_0's binary_logloss: 0.405506\n",
      "[293]\tvalid_0's binary_logloss: 0.405511\n",
      "[294]\tvalid_0's binary_logloss: 0.405437\n",
      "[295]\tvalid_0's binary_logloss: 0.405419\n",
      "[296]\tvalid_0's binary_logloss: 0.405412\n",
      "[297]\tvalid_0's binary_logloss: 0.405382\n",
      "[298]\tvalid_0's binary_logloss: 0.405278\n",
      "[299]\tvalid_0's binary_logloss: 0.405276\n",
      "[300]\tvalid_0's binary_logloss: 0.405263\n",
      "[301]\tvalid_0's binary_logloss: 0.40525\n",
      "[302]\tvalid_0's binary_logloss: 0.40525\n",
      "[303]\tvalid_0's binary_logloss: 0.405253\n",
      "[304]\tvalid_0's binary_logloss: 0.405256\n",
      "[305]\tvalid_0's binary_logloss: 0.405261\n",
      "[306]\tvalid_0's binary_logloss: 0.405229\n",
      "[307]\tvalid_0's binary_logloss: 0.405228\n",
      "[308]\tvalid_0's binary_logloss: 0.405219\n",
      "[309]\tvalid_0's binary_logloss: 0.405202\n",
      "[310]\tvalid_0's binary_logloss: 0.405199\n",
      "[311]\tvalid_0's binary_logloss: 0.405185\n",
      "[312]\tvalid_0's binary_logloss: 0.405179\n",
      "[313]\tvalid_0's binary_logloss: 0.405187\n",
      "[314]\tvalid_0's binary_logloss: 0.405147\n",
      "[315]\tvalid_0's binary_logloss: 0.405158\n",
      "[316]\tvalid_0's binary_logloss: 0.405158\n",
      "[317]\tvalid_0's binary_logloss: 0.405158\n",
      "[318]\tvalid_0's binary_logloss: 0.405156\n",
      "[319]\tvalid_0's binary_logloss: 0.405124\n",
      "[320]\tvalid_0's binary_logloss: 0.405124\n",
      "[321]\tvalid_0's binary_logloss: 0.405116\n",
      "[322]\tvalid_0's binary_logloss: 0.405114\n",
      "[323]\tvalid_0's binary_logloss: 0.405061\n",
      "[324]\tvalid_0's binary_logloss: 0.405022\n",
      "[325]\tvalid_0's binary_logloss: 0.405008\n",
      "[326]\tvalid_0's binary_logloss: 0.405002\n",
      "[327]\tvalid_0's binary_logloss: 0.404993\n",
      "[328]\tvalid_0's binary_logloss: 0.404988\n",
      "[329]\tvalid_0's binary_logloss: 0.40498\n",
      "[330]\tvalid_0's binary_logloss: 0.404978\n",
      "[331]\tvalid_0's binary_logloss: 0.404999\n",
      "[332]\tvalid_0's binary_logloss: 0.404986\n",
      "[333]\tvalid_0's binary_logloss: 0.404974\n",
      "[334]\tvalid_0's binary_logloss: 0.404933\n",
      "[335]\tvalid_0's binary_logloss: 0.404943\n",
      "[336]\tvalid_0's binary_logloss: 0.404961\n",
      "[337]\tvalid_0's binary_logloss: 0.404948\n",
      "[338]\tvalid_0's binary_logloss: 0.404954\n",
      "[339]\tvalid_0's binary_logloss: 0.40497\n",
      "[340]\tvalid_0's binary_logloss: 0.404976\n",
      "[341]\tvalid_0's binary_logloss: 0.404955\n",
      "[342]\tvalid_0's binary_logloss: 0.404953\n",
      "[343]\tvalid_0's binary_logloss: 0.404921\n",
      "[344]\tvalid_0's binary_logloss: 0.404918\n",
      "[345]\tvalid_0's binary_logloss: 0.404915\n",
      "[346]\tvalid_0's binary_logloss: 0.40492\n",
      "[347]\tvalid_0's binary_logloss: 0.404926\n",
      "[348]\tvalid_0's binary_logloss: 0.404932\n",
      "[349]\tvalid_0's binary_logloss: 0.404872\n",
      "[350]\tvalid_0's binary_logloss: 0.404877\n",
      "[351]\tvalid_0's binary_logloss: 0.404882\n",
      "[352]\tvalid_0's binary_logloss: 0.404896\n",
      "[353]\tvalid_0's binary_logloss: 0.4049\n",
      "[354]\tvalid_0's binary_logloss: 0.404899\n",
      "[355]\tvalid_0's binary_logloss: 0.404904\n",
      "[356]\tvalid_0's binary_logloss: 0.404892\n",
      "[357]\tvalid_0's binary_logloss: 0.40491\n",
      "[358]\tvalid_0's binary_logloss: 0.404915\n",
      "[359]\tvalid_0's binary_logloss: 0.40492\n",
      "[360]\tvalid_0's binary_logloss: 0.404919\n",
      "[361]\tvalid_0's binary_logloss: 0.404916\n",
      "[362]\tvalid_0's binary_logloss: 0.404901\n",
      "[363]\tvalid_0's binary_logloss: 0.404883\n",
      "[364]\tvalid_0's binary_logloss: 0.404891\n",
      "[365]\tvalid_0's binary_logloss: 0.404891\n",
      "[366]\tvalid_0's binary_logloss: 0.404889\n",
      "[367]\tvalid_0's binary_logloss: 0.404888\n",
      "[368]\tvalid_0's binary_logloss: 0.404839\n",
      "[369]\tvalid_0's binary_logloss: 0.404787\n",
      "[370]\tvalid_0's binary_logloss: 0.404779\n",
      "[371]\tvalid_0's binary_logloss: 0.40478\n",
      "[372]\tvalid_0's binary_logloss: 0.404745\n",
      "[373]\tvalid_0's binary_logloss: 0.404742\n",
      "[374]\tvalid_0's binary_logloss: 0.404743\n",
      "[375]\tvalid_0's binary_logloss: 0.404756\n",
      "[376]\tvalid_0's binary_logloss: 0.404738\n",
      "[377]\tvalid_0's binary_logloss: 0.404715\n",
      "[378]\tvalid_0's binary_logloss: 0.404721\n",
      "[379]\tvalid_0's binary_logloss: 0.404713\n",
      "[380]\tvalid_0's binary_logloss: 0.404692\n",
      "[381]\tvalid_0's binary_logloss: 0.40468\n",
      "[382]\tvalid_0's binary_logloss: 0.404672\n",
      "[383]\tvalid_0's binary_logloss: 0.404674\n",
      "[384]\tvalid_0's binary_logloss: 0.404675\n",
      "[385]\tvalid_0's binary_logloss: 0.404648\n",
      "[386]\tvalid_0's binary_logloss: 0.404574\n",
      "[387]\tvalid_0's binary_logloss: 0.404538\n",
      "[388]\tvalid_0's binary_logloss: 0.404537\n",
      "[389]\tvalid_0's binary_logloss: 0.404548\n",
      "[390]\tvalid_0's binary_logloss: 0.40456\n",
      "[391]\tvalid_0's binary_logloss: 0.404558\n",
      "[392]\tvalid_0's binary_logloss: 0.404555\n",
      "[393]\tvalid_0's binary_logloss: 0.404554\n",
      "[394]\tvalid_0's binary_logloss: 0.404556\n",
      "[395]\tvalid_0's binary_logloss: 0.404554\n",
      "[396]\tvalid_0's binary_logloss: 0.404554\n",
      "[397]\tvalid_0's binary_logloss: 0.404564\n",
      "[398]\tvalid_0's binary_logloss: 0.404559\n",
      "[399]\tvalid_0's binary_logloss: 0.404517\n",
      "[400]\tvalid_0's binary_logloss: 0.404505\n",
      "[401]\tvalid_0's binary_logloss: 0.404498\n",
      "[402]\tvalid_0's binary_logloss: 0.404479\n",
      "[403]\tvalid_0's binary_logloss: 0.404476\n",
      "[404]\tvalid_0's binary_logloss: 0.404474\n",
      "[405]\tvalid_0's binary_logloss: 0.404473\n",
      "[406]\tvalid_0's binary_logloss: 0.404452\n",
      "[407]\tvalid_0's binary_logloss: 0.404449\n",
      "[408]\tvalid_0's binary_logloss: 0.404449\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[409]\tvalid_0's binary_logloss: 0.404446\n",
      "[410]\tvalid_0's binary_logloss: 0.404444\n",
      "[411]\tvalid_0's binary_logloss: 0.40444\n",
      "[412]\tvalid_0's binary_logloss: 0.404452\n",
      "[413]\tvalid_0's binary_logloss: 0.40445\n",
      "[414]\tvalid_0's binary_logloss: 0.404454\n",
      "[415]\tvalid_0's binary_logloss: 0.404451\n",
      "[416]\tvalid_0's binary_logloss: 0.404458\n",
      "[417]\tvalid_0's binary_logloss: 0.404477\n",
      "[418]\tvalid_0's binary_logloss: 0.404481\n",
      "[419]\tvalid_0's binary_logloss: 0.404475\n",
      "[420]\tvalid_0's binary_logloss: 0.404475\n",
      "[421]\tvalid_0's binary_logloss: 0.404472\n",
      "[422]\tvalid_0's binary_logloss: 0.404473\n",
      "[423]\tvalid_0's binary_logloss: 0.404445\n",
      "[424]\tvalid_0's binary_logloss: 0.40439\n",
      "[425]\tvalid_0's binary_logloss: 0.404391\n",
      "[426]\tvalid_0's binary_logloss: 0.404378\n",
      "[427]\tvalid_0's binary_logloss: 0.404374\n",
      "[428]\tvalid_0's binary_logloss: 0.404372\n",
      "[429]\tvalid_0's binary_logloss: 0.404378\n",
      "[430]\tvalid_0's binary_logloss: 0.40438\n",
      "[431]\tvalid_0's binary_logloss: 0.404392\n",
      "[432]\tvalid_0's binary_logloss: 0.404366\n",
      "[433]\tvalid_0's binary_logloss: 0.40436\n",
      "[434]\tvalid_0's binary_logloss: 0.404366\n",
      "[435]\tvalid_0's binary_logloss: 0.404361\n",
      "[436]\tvalid_0's binary_logloss: 0.404346\n",
      "[437]\tvalid_0's binary_logloss: 0.404334\n",
      "[438]\tvalid_0's binary_logloss: 0.404303\n",
      "[439]\tvalid_0's binary_logloss: 0.404313\n",
      "[440]\tvalid_0's binary_logloss: 0.404324\n",
      "[441]\tvalid_0's binary_logloss: 0.404292\n",
      "[442]\tvalid_0's binary_logloss: 0.404301\n",
      "[443]\tvalid_0's binary_logloss: 0.404295\n",
      "[444]\tvalid_0's binary_logloss: 0.404249\n",
      "[445]\tvalid_0's binary_logloss: 0.404254\n",
      "[446]\tvalid_0's binary_logloss: 0.404266\n",
      "[447]\tvalid_0's binary_logloss: 0.404263\n",
      "[448]\tvalid_0's binary_logloss: 0.404255\n",
      "[449]\tvalid_0's binary_logloss: 0.404255\n",
      "[450]\tvalid_0's binary_logloss: 0.404257\n",
      "[451]\tvalid_0's binary_logloss: 0.404256\n",
      "[452]\tvalid_0's binary_logloss: 0.404196\n",
      "[453]\tvalid_0's binary_logloss: 0.404201\n",
      "[454]\tvalid_0's binary_logloss: 0.404203\n",
      "[455]\tvalid_0's binary_logloss: 0.404189\n",
      "[456]\tvalid_0's binary_logloss: 0.404194\n",
      "[457]\tvalid_0's binary_logloss: 0.404185\n",
      "[458]\tvalid_0's binary_logloss: 0.404183\n",
      "[459]\tvalid_0's binary_logloss: 0.404167\n",
      "[460]\tvalid_0's binary_logloss: 0.404183\n",
      "[461]\tvalid_0's binary_logloss: 0.404206\n",
      "[462]\tvalid_0's binary_logloss: 0.404206\n",
      "[463]\tvalid_0's binary_logloss: 0.404189\n",
      "[464]\tvalid_0's binary_logloss: 0.404175\n",
      "[465]\tvalid_0's binary_logloss: 0.404124\n",
      "[466]\tvalid_0's binary_logloss: 0.404125\n",
      "[467]\tvalid_0's binary_logloss: 0.404108\n",
      "[468]\tvalid_0's binary_logloss: 0.404115\n",
      "[469]\tvalid_0's binary_logloss: 0.404105\n",
      "[470]\tvalid_0's binary_logloss: 0.404121\n",
      "[471]\tvalid_0's binary_logloss: 0.40411\n",
      "[472]\tvalid_0's binary_logloss: 0.404105\n",
      "[473]\tvalid_0's binary_logloss: 0.404105\n",
      "[474]\tvalid_0's binary_logloss: 0.404103\n",
      "[475]\tvalid_0's binary_logloss: 0.404107\n",
      "[476]\tvalid_0's binary_logloss: 0.404112\n",
      "[477]\tvalid_0's binary_logloss: 0.404118\n",
      "[478]\tvalid_0's binary_logloss: 0.404112\n",
      "[479]\tvalid_0's binary_logloss: 0.404112\n",
      "[480]\tvalid_0's binary_logloss: 0.404103\n",
      "[481]\tvalid_0's binary_logloss: 0.404107\n",
      "[482]\tvalid_0's binary_logloss: 0.404119\n",
      "[483]\tvalid_0's binary_logloss: 0.404129\n",
      "[484]\tvalid_0's binary_logloss: 0.40411\n",
      "[485]\tvalid_0's binary_logloss: 0.404107\n",
      "[486]\tvalid_0's binary_logloss: 0.404105\n",
      "[487]\tvalid_0's binary_logloss: 0.404099\n",
      "[488]\tvalid_0's binary_logloss: 0.404103\n",
      "[489]\tvalid_0's binary_logloss: 0.404095\n",
      "[490]\tvalid_0's binary_logloss: 0.404092\n",
      "[491]\tvalid_0's binary_logloss: 0.404099\n",
      "[492]\tvalid_0's binary_logloss: 0.404091\n",
      "[493]\tvalid_0's binary_logloss: 0.404098\n",
      "[494]\tvalid_0's binary_logloss: 0.404091\n",
      "[495]\tvalid_0's binary_logloss: 0.404073\n",
      "[496]\tvalid_0's binary_logloss: 0.404043\n",
      "[497]\tvalid_0's binary_logloss: 0.404046\n",
      "[498]\tvalid_0's binary_logloss: 0.404029\n",
      "[499]\tvalid_0's binary_logloss: 0.404042\n",
      "[500]\tvalid_0's binary_logloss: 0.404046\n",
      "[501]\tvalid_0's binary_logloss: 0.404039\n",
      "[502]\tvalid_0's binary_logloss: 0.404036\n",
      "[503]\tvalid_0's binary_logloss: 0.404046\n",
      "[504]\tvalid_0's binary_logloss: 0.404036\n",
      "[505]\tvalid_0's binary_logloss: 0.404029\n",
      "[506]\tvalid_0's binary_logloss: 0.404001\n",
      "[507]\tvalid_0's binary_logloss: 0.403992\n",
      "[508]\tvalid_0's binary_logloss: 0.403995\n",
      "[509]\tvalid_0's binary_logloss: 0.404\n",
      "[510]\tvalid_0's binary_logloss: 0.403991\n",
      "[511]\tvalid_0's binary_logloss: 0.403991\n",
      "[512]\tvalid_0's binary_logloss: 0.403996\n",
      "[513]\tvalid_0's binary_logloss: 0.404003\n",
      "[514]\tvalid_0's binary_logloss: 0.404006\n",
      "[515]\tvalid_0's binary_logloss: 0.404014\n",
      "[516]\tvalid_0's binary_logloss: 0.404017\n",
      "[517]\tvalid_0's binary_logloss: 0.404024\n",
      "[518]\tvalid_0's binary_logloss: 0.404034\n",
      "[519]\tvalid_0's binary_logloss: 0.404018\n",
      "[520]\tvalid_0's binary_logloss: 0.403994\n",
      "[521]\tvalid_0's binary_logloss: 0.403992\n",
      "[522]\tvalid_0's binary_logloss: 0.403996\n",
      "[523]\tvalid_0's binary_logloss: 0.403993\n",
      "[524]\tvalid_0's binary_logloss: 0.403995\n",
      "[525]\tvalid_0's binary_logloss: 0.403989\n",
      "[526]\tvalid_0's binary_logloss: 0.403984\n",
      "[527]\tvalid_0's binary_logloss: 0.403976\n",
      "[528]\tvalid_0's binary_logloss: 0.403981\n",
      "[529]\tvalid_0's binary_logloss: 0.403963\n",
      "[530]\tvalid_0's binary_logloss: 0.403964\n",
      "[531]\tvalid_0's binary_logloss: 0.40392\n",
      "[532]\tvalid_0's binary_logloss: 0.403916\n",
      "[533]\tvalid_0's binary_logloss: 0.403896\n",
      "[534]\tvalid_0's binary_logloss: 0.403897\n",
      "[535]\tvalid_0's binary_logloss: 0.403889\n",
      "[536]\tvalid_0's binary_logloss: 0.403884\n",
      "[537]\tvalid_0's binary_logloss: 0.403861\n",
      "[538]\tvalid_0's binary_logloss: 0.403862\n",
      "[539]\tvalid_0's binary_logloss: 0.40386\n",
      "[540]\tvalid_0's binary_logloss: 0.403846\n",
      "[541]\tvalid_0's binary_logloss: 0.403838\n",
      "[542]\tvalid_0's binary_logloss: 0.403841\n",
      "[543]\tvalid_0's binary_logloss: 0.403843\n",
      "[544]\tvalid_0's binary_logloss: 0.403836\n",
      "[545]\tvalid_0's binary_logloss: 0.403835\n",
      "[546]\tvalid_0's binary_logloss: 0.403814\n",
      "[547]\tvalid_0's binary_logloss: 0.403813\n",
      "[548]\tvalid_0's binary_logloss: 0.403799\n",
      "[549]\tvalid_0's binary_logloss: 0.403762\n",
      "[550]\tvalid_0's binary_logloss: 0.403752\n",
      "[551]\tvalid_0's binary_logloss: 0.403754\n",
      "[552]\tvalid_0's binary_logloss: 0.403709\n",
      "[553]\tvalid_0's binary_logloss: 0.403718\n",
      "[554]\tvalid_0's binary_logloss: 0.40372\n",
      "[555]\tvalid_0's binary_logloss: 0.403734\n",
      "[556]\tvalid_0's binary_logloss: 0.403744\n",
      "[557]\tvalid_0's binary_logloss: 0.403752\n",
      "[558]\tvalid_0's binary_logloss: 0.40375\n",
      "[559]\tvalid_0's binary_logloss: 0.403754\n",
      "[560]\tvalid_0's binary_logloss: 0.403757\n",
      "[561]\tvalid_0's binary_logloss: 0.403762\n",
      "[562]\tvalid_0's binary_logloss: 0.403767\n",
      "[563]\tvalid_0's binary_logloss: 0.403759\n",
      "[564]\tvalid_0's binary_logloss: 0.403768\n",
      "[565]\tvalid_0's binary_logloss: 0.403776\n",
      "[566]\tvalid_0's binary_logloss: 0.403776\n",
      "[567]\tvalid_0's binary_logloss: 0.403787\n",
      "[568]\tvalid_0's binary_logloss: 0.403787\n",
      "[569]\tvalid_0's binary_logloss: 0.40378\n",
      "[570]\tvalid_0's binary_logloss: 0.403789\n",
      "[571]\tvalid_0's binary_logloss: 0.403793\n",
      "[572]\tvalid_0's binary_logloss: 0.403793\n",
      "[573]\tvalid_0's binary_logloss: 0.403804\n",
      "[574]\tvalid_0's binary_logloss: 0.403809\n",
      "[575]\tvalid_0's binary_logloss: 0.403807\n",
      "[576]\tvalid_0's binary_logloss: 0.403807\n",
      "[577]\tvalid_0's binary_logloss: 0.40381\n",
      "[578]\tvalid_0's binary_logloss: 0.403788\n",
      "[579]\tvalid_0's binary_logloss: 0.403764\n",
      "[580]\tvalid_0's binary_logloss: 0.403768\n",
      "[581]\tvalid_0's binary_logloss: 0.403779\n",
      "[582]\tvalid_0's binary_logloss: 0.403774\n",
      "[583]\tvalid_0's binary_logloss: 0.403754\n",
      "[584]\tvalid_0's binary_logloss: 0.403753\n",
      "[585]\tvalid_0's binary_logloss: 0.40375\n",
      "[586]\tvalid_0's binary_logloss: 0.403753\n",
      "[587]\tvalid_0's binary_logloss: 0.403758\n",
      "[588]\tvalid_0's binary_logloss: 0.403755\n",
      "[589]\tvalid_0's binary_logloss: 0.403723\n",
      "[590]\tvalid_0's binary_logloss: 0.403723\n",
      "[591]\tvalid_0's binary_logloss: 0.403718\n",
      "[592]\tvalid_0's binary_logloss: 0.403714\n",
      "[593]\tvalid_0's binary_logloss: 0.403707\n",
      "[594]\tvalid_0's binary_logloss: 0.403709\n",
      "[595]\tvalid_0's binary_logloss: 0.403716\n",
      "[596]\tvalid_0's binary_logloss: 0.403707\n",
      "[597]\tvalid_0's binary_logloss: 0.403676\n",
      "[598]\tvalid_0's binary_logloss: 0.403678\n",
      "[599]\tvalid_0's binary_logloss: 0.403652\n",
      "[600]\tvalid_0's binary_logloss: 0.403656\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[599]\tvalid_0's binary_logloss: 0.403652\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "params={}\n",
    "params['learning_rate']= 0.175\n",
    "params['boosting_type']='gbdt'\n",
    "params['objective']='binary'\n",
    "params['metric']='binary_logloss'\n",
    "params['sub_feature']=0.5\n",
    "params['num_leaves']= 10\n",
    "params['min_data']=30\n",
    "params['max_depth']=10\n",
    "d_train = lgb.Dataset(x_train, label=y_train )\n",
    "d_test =  lgb.Dataset( x_test, label= y_test)\n",
    "#d_train=lgb.Dataset(X,label=Y)\n",
    "\n",
    "evals_result = {}\n",
    "\n",
    "model2=lgb.train(params,d_train,800,\n",
    "                valid_sets=d_test,verbose_eval=True,\n",
    "                early_stopping_rounds=50,evals_result=evals_result)\n",
    "\n",
    "ax = lgb.plot_metric(evals_result, metric='binary_logloss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'bin_0', 'bin_1', 'bin_2', 'bin_3', 'bin_4', 'nom_0', 'nom_1',\n",
       "       'nom_2', 'nom_3', 'nom_4', 'nom_5', 'nom_6', 'nom_7', 'nom_8', 'nom_9',\n",
       "       'ord_0', 'ord_1', 'ord_2', 'ord_3', 'ord_4', 'ord_5', 'day_sin',\n",
       "       'day_cos', 'month_sin', 'month_cos'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_df_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_df_test=encoded_df_test.drop(['id'],axis=1)\n",
    "y_pred=model.predict(encoded_df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.29284535, 0.2407599 , 0.14351193, ..., 0.34842298, 0.1881282 ,\n",
       "       0.21137527])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400000"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(0,100):\n",
    "    if (y_pred[i] >= 0.5):\n",
    "        y_pred[i] = 1\n",
    "    else:\n",
    "        y_pred[i] =0\n",
    "len(y_pred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.28 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sample = pd.read_csv(\"sample_submission.csv\")\n",
    "sample.loc[:, \"target\"] = y_pred\n",
    "sample.to_csv(\"submission_using_lgbm.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import randint as sp_randint\n",
    "from scipy.stats import uniform as sp_uniform\n",
    "param_test ={'num_leaves': sp_randint(6, 50), \n",
    "             'min_child_samples': sp_randint(100, 500), \n",
    "             'min_child_weight': [1e-5, 1e-3, 1e-2, 1e-1, 1, 1e1, 1e2, 1e3, 1e4],\n",
    "             'subsample': sp_uniform(loc=0.2, scale=0.8), \n",
    "             'colsample_bytree': sp_uniform(loc=0.4, scale=0.6),\n",
    "             'reg_alpha': [0, 1e-1, 1, 2, 5, 7, 10, 50, 100],\n",
    "             'reg_lambda': [0, 1e-1, 1, 5, 10, 20, 50, 100]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "\n",
    "#n_estimators is set to a \"large value\". The actual number of trees build will depend on early stopping and 5000 define only the absolute maximum\n",
    "clf = lgb.LGBMClassifier(max_depth=-1, random_state=314, silent=True, metric='None', n_jobs=4, n_estimators=5000)\n",
    "gs = RandomizedSearchCV(\n",
    "    estimator=clf, param_distributions=param_test, \n",
    "    n_iter=n_HP_points_to_test,\n",
    "    scoring='roc_auc',\n",
    "    cv=3,\n",
    "    refit=True,\n",
    "    random_state=314,\n",
    "    verbose=True)\n",
    "\n",
    "gs.fit(X_train, y_train, **fit_params)\n",
    "print('Best score reached: {} with params: {} '.format(gs.best_score_, gs.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridParams = {\n",
    "    'learning_rate': [0.005],\n",
    "    'n_estimators': [40],\n",
    "    'num_leaves': [6,8,12,16],\n",
    "    'boosting_type' : ['gbdt'],\n",
    "    'objective' : ['binary'],\n",
    "    'random_state' : [501], # Updated from 'seed'\n",
    "    'colsample_bytree' : [0.65, 0.66],\n",
    "    'subsample' : [0.7,0.75],\n",
    "    'reg_alpha' : [1,1.2],\n",
    "    'reg_lambda' : [1,1.2,1.4],\n",
    "    }\n",
    "\n",
    "# Create classifier to use. Note that parameters have to be input manually\n",
    "# not as a dict!\n",
    "mdl = lgb.LGBMClassifier(boosting_type= 'gbdt',\n",
    "          objective = 'binary',\n",
    "          n_jobs = 3, # Updated from 'nthread'\n",
    "          silent = True,\n",
    "          max_depth = params['max_depth'],\n",
    "          max_bin = params['max_bin'],\n",
    "          subsample_for_bin = params['subsample_for_bin'],\n",
    "          subsample = params['subsample'],\n",
    "          subsample_freq = params['subsample_freq'],\n",
    "          min_split_gain = params['min_split_gain'],\n",
    "          min_child_weight = params['min_child_weight'],\n",
    "          min_child_samples = params['min_child_samples'],\n",
    "          scale_pos_weight = params['scale_pos_weight'])\n",
    "\n",
    "mdl.get_params().keys()\n",
    "\n",
    "# Create the grid\n",
    "grid = GridSearchCV(mdl, gridParams,\n",
    "                    verbose=0,\n",
    "                    cv=4,\n",
    "                    n_jobs=2)\n",
    "# Run the grid\n",
    "grid.fit(allTrainData, allTrainLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [col for col in df_train.columns if col not in ['target', 'ID_code']]\n",
    "X_test = df_test[features].values\n",
    "feature_importance_df = pd.DataFrame()\n",
    "predictions = df_test[['ID_code']]\n",
    "\n",
    "for fold, (trn_idx, val_idx) in enumerate(skf.split(df_train, df_train['target'])):\n",
    "    print(\"FOLD: \", fold, \"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, y_train = df_train.iloc[trn_idx][features], df_train.iloc[trn_idx]['target']\n",
    "    X_valid, y_valid = df_train.iloc[val_idx][features], df_train.iloc[val_idx]['target']\n",
    "    \n",
    "    N = 5\n",
    "    p_valid = 0\n",
    "    yp = 0\n",
    "    \n",
    "    for i in range(N):\n",
    "        \n",
    "        trn_data = lgb.Dataset(X_train, label = y_train)\n",
    "        val_data = lgb.Dataset(X_valid, label = y_valid)\n",
    "        \n",
    "        \n",
    "        \n",
    "        lgb_clf = lgb.train(lgb_params,\n",
    "                   trn_data,\n",
    "                   100000,\n",
    "                   valid_sets = [trn_data, val_data],\n",
    "                    verbose_eval = 5000,\n",
    "                    early_stopping_rounds = 3000)\n",
    "        \n",
    "        p_valid += lgb_clf.predict(X_valid)\n",
    "        yp += lgb_clf.predict(X_test)\n",
    "    \n",
    "    \n",
    "    #Get importance of the fold when predicting test set\n",
    "    fold_importance_df = pd.DataFrame()\n",
    "    fold_importance_df[\"feature\"] = features\n",
    "    fold_importance_df[\"importance\"] = lgb_clf.feature_importance()\n",
    "    fold_importance_df[\"fold\"] = fold + 1\n",
    "    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "    predictions['fold{}'.format(fold+1)] = yp/N"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
